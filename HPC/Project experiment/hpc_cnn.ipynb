{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "PnZPsRgIcm5A"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "# Load your dataset\n",
        "df = pd.read_csv('PAT_Dataset.csv')\n",
        "\n",
        "# Shuffle the dataset\n",
        "df = shuffle(df, random_state=42)\n",
        "\n",
        "# Columns containing the target variables\n",
        "target_columns = [\n",
        "    'steady_state_temp_L0', 'steady_state_temp_L1', 'router_avg_temp_L0', 'router_avg_temp_L1',\n",
        "    'core_avg_temp_L0', 'core_avg_temp_L1', 'mem_avg_temp_L0', 'mem_avg_temp_L1',\n",
        "    'total_area', 'avg_power', 'avg_cores_power', 'avg_routers_power', 'avg_power_per_router',\n",
        "    'layer_area', 'area_per_core'\n",
        "]\n",
        "\n",
        "# Identify categorical columns\n",
        "categorical_columns = ['routing_type', 'selection_strategy', 'traffic_type']\n",
        "\n",
        "# One-hot encode categorical columns\n",
        "X = pd.get_dummies(df.drop(columns=target_columns), columns=categorical_columns, drop_first=True)\n",
        "y = df[target_columns]\n",
        "\n",
        "# Split the data into training and test sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize StandardScaler\n",
        "scaler_X = StandardScaler()\n",
        "scaler_y = StandardScaler()\n",
        "\n",
        "# Scale the feature and target data\n",
        "X_train_scaled = scaler_X.fit_transform(X_train)\n",
        "X_test_scaled = scaler_X.transform(X_test)\n",
        "y_train_scaled = scaler_y.fit_transform(y_train)\n",
        "y_test_scaled = scaler_y.transform(y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "# Reshape the data to fit a CNN input\n",
        "# The CNN model expects a 3D input shape (samples, time steps, features), so we reshape X_train_scaled and X_test_scaled\n",
        "X_train_cnn = X_train_scaled.reshape(X_train_scaled.shape[0], X_train_scaled.shape[1], 1)  # Add 1 for the single \"channel\"\n",
        "X_test_cnn = X_test_scaled.reshape(X_test_scaled.shape[0], X_test_scaled.shape[1], 1)\n",
        "\n",
        "# Build a simple CNN model\n",
        "cnn_model = Sequential()\n",
        "\n",
        "# Add 1D convolutional layers with padding='same' to avoid shrinking the input size\n",
        "cnn_model.add(Conv1D(filters=64, kernel_size=3, activation='relu', padding='same', input_shape=(X_train_cnn.shape[1], 1)))\n",
        "cnn_model.add(MaxPooling1D(pool_size=2))\n",
        "\n",
        "cnn_model.add(Conv1D(filters=128, kernel_size=3, activation='relu', padding='same'))\n",
        "cnn_model.add(MaxPooling1D(pool_size=2))\n",
        "\n",
        "# Flatten the output of the convolutions\n",
        "cnn_model.add(Flatten())\n",
        "\n",
        "# Add dense layers for regression\n",
        "cnn_model.add(Dense(128, activation='relu'))\n",
        "cnn_model.add(Dense(64, activation='relu'))\n",
        "cnn_model.add(Dense(len(target_columns)))  # Output layer for all targets at once\n",
        "\n",
        "# Compile the CNN model\n",
        "cnn_model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Train the model\n",
        "cnn_model.fit(X_train_cnn, y_train_scaled, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Predict using the trained CNN model\n",
        "y_pred_cnn_scaled = cnn_model.predict(X_test_cnn)\n",
        "\n",
        "# Prepare a list to store the evaluation results\n",
        "cnn_evaluation_results = []\n",
        "\n",
        "# Evaluate the model for each target variable separately\n",
        "print(\"CNN Performance (per target variable):\")\n",
        "for i, target in enumerate(target_columns):\n",
        "    y_test_target = y_test_scaled[:, i]  # Get actual values for target i\n",
        "    y_pred_target = y_pred_cnn_scaled[:, i]  # Get predicted values for target i\n",
        "\n",
        "    # Calculate performance metrics\n",
        "    mse = mean_squared_error(y_test_target, y_pred_target)\n",
        "    mae = mean_absolute_error(y_test_target, y_pred_target)\n",
        "    r2 = r2_score(y_test_target, y_pred_target)\n",
        "\n",
        "    # Append results to the list\n",
        "    cnn_evaluation_results.append({\n",
        "        'algorithm': 'CNN',\n",
        "        'target': target,\n",
        "        'MSE': mse,\n",
        "        'MAE': mae,\n",
        "        'R²': r2\n",
        "    })\n",
        "\n",
        "    # Print results for the current target\n",
        "    print(f\"\\nTarget: {target}\")\n",
        "    print(\"MSE:\", mse)\n",
        "    print(\"MAE:\", mae)\n",
        "    print(\"R²:\", r2)\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "# Convert the results list to a DataFrame\n",
        "cnn_evaluation_df = pd.DataFrame(cnn_evaluation_results)\n",
        "\n",
        "# Display the CNN evaluation results DataFrame\n",
        "print(\"\\nCNN Evaluation Results DataFrame:\")\n",
        "print(cnn_evaluation_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21uOq-JRRV0b",
        "outputId": "d5b446f5-b403-49d0-8cc8-f0af5b7fc483"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.4400 - val_loss: 0.1242\n",
            "Epoch 2/10\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1163 - val_loss: 0.0816\n",
            "Epoch 3/10\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0808 - val_loss: 0.0680\n",
            "Epoch 4/10\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0600 - val_loss: 0.0433\n",
            "Epoch 5/10\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0419 - val_loss: 0.0337\n",
            "Epoch 6/10\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0326 - val_loss: 0.0260\n",
            "Epoch 7/10\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0236 - val_loss: 0.0167\n",
            "Epoch 8/10\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0161 - val_loss: 0.0149\n",
            "Epoch 9/10\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0137 - val_loss: 0.0129\n",
            "Epoch 10/10\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0142 - val_loss: 0.0102\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "CNN Performance (per target variable):\n",
            "\n",
            "Target: steady_state_temp_L0\n",
            "MSE: 0.02096937110308532\n",
            "MAE: 0.08261156588842983\n",
            "R²: 0.9781676955569012\n",
            "------------------------------\n",
            "\n",
            "Target: steady_state_temp_L1\n",
            "MSE: 0.020049396778810943\n",
            "MAE: 0.07894665584945136\n",
            "R²: 0.9791335486174971\n",
            "------------------------------\n",
            "\n",
            "Target: router_avg_temp_L0\n",
            "MSE: 0.016368692828674522\n",
            "MAE: 0.08571156224689672\n",
            "R²: 0.9835818883826399\n",
            "------------------------------\n",
            "\n",
            "Target: router_avg_temp_L1\n",
            "MSE: 0.011438306651250988\n",
            "MAE: 0.06487793952148743\n",
            "R²: 0.9890909323629433\n",
            "------------------------------\n",
            "\n",
            "Target: core_avg_temp_L0\n",
            "MSE: 0.019988799019686233\n",
            "MAE: 0.09852971499943562\n",
            "R²: 0.9797093486489623\n",
            "------------------------------\n",
            "\n",
            "Target: core_avg_temp_L1\n",
            "MSE: 0.011870291127710835\n",
            "MAE: 0.07088043761091199\n",
            "R²: 0.9882729838454228\n",
            "------------------------------\n",
            "\n",
            "Target: mem_avg_temp_L0\n",
            "MSE: 0.023863576063990338\n",
            "MAE: 0.10737464005255769\n",
            "R²: 0.976250133818812\n",
            "------------------------------\n",
            "\n",
            "Target: mem_avg_temp_L1\n",
            "MSE: 0.011545531826022946\n",
            "MAE: 0.06548455419603429\n",
            "R²: 0.9887678373072305\n",
            "------------------------------\n",
            "\n",
            "Target: total_area\n",
            "MSE: 0.001406794509139666\n",
            "MAE: 0.029944346964333887\n",
            "R²: 0.9986242580045358\n",
            "------------------------------\n",
            "\n",
            "Target: avg_power\n",
            "MSE: 0.0016974801501843464\n",
            "MAE: 0.030097717974122765\n",
            "R²: 0.9983011576398029\n",
            "------------------------------\n",
            "\n",
            "Target: avg_cores_power\n",
            "MSE: 0.001330102212230966\n",
            "MAE: 0.028484001763148314\n",
            "R²: 0.9986782513342043\n",
            "------------------------------\n",
            "\n",
            "Target: avg_routers_power\n",
            "MSE: 0.0032203148335788073\n",
            "MAE: 0.03893102527267633\n",
            "R²: 0.996703912813066\n",
            "------------------------------\n",
            "\n",
            "Target: avg_power_per_router\n",
            "MSE: 0.01329662734445782\n",
            "MAE: 0.08820980961569752\n",
            "R²: 0.9864068144074941\n",
            "------------------------------\n",
            "\n",
            "Target: layer_area\n",
            "MSE: 0.001159955456948874\n",
            "MAE: 0.02685491314204353\n",
            "R²: 0.9988656482450251\n",
            "------------------------------\n",
            "\n",
            "Target: area_per_core\n",
            "MSE: 0.00024272287865772114\n",
            "MAE: 0.01153039067196583\n",
            "R²: 0.0\n",
            "------------------------------\n",
            "\n",
            "CNN Evaluation Results DataFrame:\n",
            "   algorithm                target       MSE       MAE        R²\n",
            "0        CNN  steady_state_temp_L0  0.020969  0.082612  0.978168\n",
            "1        CNN  steady_state_temp_L1  0.020049  0.078947  0.979134\n",
            "2        CNN    router_avg_temp_L0  0.016369  0.085712  0.983582\n",
            "3        CNN    router_avg_temp_L1  0.011438  0.064878  0.989091\n",
            "4        CNN      core_avg_temp_L0  0.019989  0.098530  0.979709\n",
            "5        CNN      core_avg_temp_L1  0.011870  0.070880  0.988273\n",
            "6        CNN       mem_avg_temp_L0  0.023864  0.107375  0.976250\n",
            "7        CNN       mem_avg_temp_L1  0.011546  0.065485  0.988768\n",
            "8        CNN            total_area  0.001407  0.029944  0.998624\n",
            "9        CNN             avg_power  0.001697  0.030098  0.998301\n",
            "10       CNN       avg_cores_power  0.001330  0.028484  0.998678\n",
            "11       CNN     avg_routers_power  0.003220  0.038931  0.996704\n",
            "12       CNN  avg_power_per_router  0.013297  0.088210  0.986407\n",
            "13       CNN            layer_area  0.001160  0.026855  0.998866\n",
            "14       CNN         area_per_core  0.000243  0.011530  0.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Define the new data as a DataFrame\n",
        "new_data = pd.DataFrame({\n",
        "    'dimx': [14],\n",
        "    'dimy': [11],\n",
        "    'dimz': [2],\n",
        "    'buffer_size': [10],\n",
        "    'packet_size_min': [4],\n",
        "    'packet_size_max': [8],\n",
        "    'routing_type_oe_3d': [1],  # Make sure to align with the encoded columns\n",
        "    'selection_strategy_thermal': [1],\n",
        "    'traffic_type_random': [1],\n",
        "    'injection_rate': [0.05]\n",
        "})\n",
        "\n",
        "# Ensure all columns are present (including any missing dummy variables from the training data)\n",
        "# Missing columns in new_data are filled with 0s\n",
        "for col in X.columns:\n",
        "    if col not in new_data:\n",
        "        new_data[col] = 0\n",
        "\n",
        "# Reorder the new_data columns to match the original feature order\n",
        "new_data = new_data[X.columns]\n",
        "\n",
        "# Scale the new data using the previously fitted scaler\n",
        "new_data_scaled = scaler_X.transform(new_data)\n",
        "\n",
        "# Reshape the scaled data to fit the CNN input shape\n",
        "new_data_cnn = new_data_scaled.reshape(1, new_data_scaled.shape[1], 1)  # Shape (1, num_features, 1)\n",
        "\n",
        "# Make predictions with the CNN model\n",
        "new_data_pred_scaled = cnn_model.predict(new_data_cnn)\n",
        "\n",
        "# Inverse scale the predictions to get original scale\n",
        "new_data_pred = scaler_y.inverse_transform(new_data_pred_scaled)\n",
        "\n",
        "# Convert the prediction to a DataFrame for readability\n",
        "predictions_df = pd.DataFrame(new_data_pred, columns=target_columns)\n",
        "\n",
        "# Display the predictions\n",
        "print(\"Predictions for the new data:\")\n",
        "print(predictions_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSzYt6hVPql_",
        "outputId": "7c711c79-c240-48fe-e33e-a9eb6bc22ece"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step\n",
            "Predictions for the new data:\n",
            "   steady_state_temp_L0  steady_state_temp_L1  router_avg_temp_L0  \\\n",
            "0            143.108994            141.062057           26.920168   \n",
            "\n",
            "   router_avg_temp_L1  core_avg_temp_L0  core_avg_temp_L1  mem_avg_temp_L0  \\\n",
            "0           26.680582         26.157522         26.034374        25.874044   \n",
            "\n",
            "   mem_avg_temp_L1   total_area     avg_power  avg_cores_power  \\\n",
            "0         25.76001  718245888.0  4.409188e-07     3.453331e-07   \n",
            "\n",
            "   avg_routers_power  avg_power_per_router   layer_area  area_per_core  \n",
            "0       8.806025e-08          2.926545e-10  368154816.0      4695230.0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.layers import Dropout\n",
        "\n",
        "# Build an improved CNN model with dropout layers and deeper architecture\n",
        "cnn_model = Sequential()\n",
        "\n",
        "cnn_model.add(Conv1D(filters=64, kernel_size=3, activation='relu', padding='same', input_shape=(X_train_cnn.shape[1], 1)))\n",
        "cnn_model.add(MaxPooling1D(pool_size=2))\n",
        "cnn_model.add(Dropout(0.3))\n",
        "\n",
        "cnn_model.add(Conv1D(filters=128, kernel_size=3, activation='relu', padding='same'))\n",
        "cnn_model.add(MaxPooling1D(pool_size=2))\n",
        "cnn_model.add(Dropout(0.3))\n",
        "\n",
        "cnn_model.add(Conv1D(filters=256, kernel_size=3, activation='relu', padding='same'))\n",
        "cnn_model.add(MaxPooling1D(pool_size=2))\n",
        "cnn_model.add(Dropout(0.3))\n",
        "\n",
        "# Flatten and add dense layers for regression\n",
        "cnn_model.add(Flatten())\n",
        "cnn_model.add(Dense(128, activation='relu'))\n",
        "cnn_model.add(Dropout(0.3))\n",
        "cnn_model.add(Dense(64, activation='relu'))\n",
        "cnn_model.add(Dense(len(target_columns)))  # Output layer for all targets at once\n",
        "\n",
        "# Compile the model\n",
        "cnn_model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Set up callbacks for early stopping and learning rate reduction\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-5)\n",
        "\n",
        "# Train the model\n",
        "cnn_model.fit(X_train_cnn, y_train_scaled, epochs=50, batch_size=32, validation_split=0.2,\n",
        "              callbacks=[early_stopping, reduce_lr])\n",
        "\n",
        "# Predict using the trained CNN model\n",
        "y_pred_cnn_scaled = cnn_model.predict(X_test_cnn)\n",
        "\n",
        "# Prepare evaluation results as before\n",
        "cnn_evaluation_results = []\n",
        "print(\"CNN Performance (per target variable):\")\n",
        "\n",
        "for i, target in enumerate(target_columns):\n",
        "    y_test_target = y_test_scaled[:, i]\n",
        "    y_pred_target = y_pred_cnn_scaled[:, i]\n",
        "    mse = mean_squared_error(y_test_target, y_pred_target)\n",
        "    mae = mean_absolute_error(y_test_target, y_pred_target)\n",
        "    r2 = r2_score(y_test_target, y_pred_target)\n",
        "    cnn_evaluation_results.append({\n",
        "        'algorithm': 'CNN',\n",
        "        'target': target,\n",
        "        'MSE': mse,\n",
        "        'MAE': mae,\n",
        "        'R²': r2\n",
        "    })\n",
        "    print(f\"\\nTarget: {target}\")\n",
        "    print(\"MSE:\", mse)\n",
        "    print(\"MAE:\", mae)\n",
        "    print(\"R²:\", r2)\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "# Results DataFrame\n",
        "cnn_evaluation_df = pd.DataFrame(cnn_evaluation_results)\n",
        "print(\"\\nCNN Evaluation Results DataFrame:\")\n",
        "print(cnn_evaluation_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKPohrkDVDLe",
        "outputId": "6f02d03e-c9f3-4404-90ce-9f9dc084b015"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.5703 - val_loss: 0.1989 - learning_rate: 0.0010\n",
            "Epoch 2/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2484 - val_loss: 0.1069 - learning_rate: 0.0010\n",
            "Epoch 3/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.1773 - val_loss: 0.0833 - learning_rate: 0.0010\n",
            "Epoch 4/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1434 - val_loss: 0.0801 - learning_rate: 0.0010\n",
            "Epoch 5/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1329 - val_loss: 0.0571 - learning_rate: 0.0010\n",
            "Epoch 6/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.1214 - val_loss: 0.0584 - learning_rate: 0.0010\n",
            "Epoch 7/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.1135 - val_loss: 0.0616 - learning_rate: 0.0010\n",
            "Epoch 8/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.1039 - val_loss: 0.0426 - learning_rate: 0.0010\n",
            "Epoch 9/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0964 - val_loss: 0.0446 - learning_rate: 0.0010\n",
            "Epoch 10/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.0960 - val_loss: 0.0402 - learning_rate: 0.0010\n",
            "Epoch 11/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0892 - val_loss: 0.0347 - learning_rate: 0.0010\n",
            "Epoch 12/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0811 - val_loss: 0.0302 - learning_rate: 0.0010\n",
            "Epoch 13/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0803 - val_loss: 0.0293 - learning_rate: 0.0010\n",
            "Epoch 14/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0756 - val_loss: 0.0359 - learning_rate: 0.0010\n",
            "Epoch 15/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0789 - val_loss: 0.0322 - learning_rate: 0.0010\n",
            "Epoch 16/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0726 - val_loss: 0.0235 - learning_rate: 0.0010\n",
            "Epoch 17/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0694 - val_loss: 0.0299 - learning_rate: 0.0010\n",
            "Epoch 18/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.0702 - val_loss: 0.0285 - learning_rate: 0.0010\n",
            "Epoch 19/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0713 - val_loss: 0.0280 - learning_rate: 0.0010\n",
            "Epoch 20/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0553 - val_loss: 0.0172 - learning_rate: 2.0000e-04\n",
            "Epoch 21/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0503 - val_loss: 0.0170 - learning_rate: 2.0000e-04\n",
            "Epoch 22/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0517 - val_loss: 0.0176 - learning_rate: 2.0000e-04\n",
            "Epoch 23/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0492 - val_loss: 0.0185 - learning_rate: 2.0000e-04\n",
            "Epoch 24/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.0493 - val_loss: 0.0173 - learning_rate: 2.0000e-04\n",
            "Epoch 25/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0487 - val_loss: 0.0167 - learning_rate: 4.0000e-05\n",
            "Epoch 26/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0473 - val_loss: 0.0164 - learning_rate: 4.0000e-05\n",
            "Epoch 27/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0462 - val_loss: 0.0154 - learning_rate: 4.0000e-05\n",
            "Epoch 28/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0466 - val_loss: 0.0161 - learning_rate: 4.0000e-05\n",
            "Epoch 29/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.0485 - val_loss: 0.0155 - learning_rate: 4.0000e-05\n",
            "Epoch 30/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0457 - val_loss: 0.0157 - learning_rate: 4.0000e-05\n",
            "Epoch 31/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0464 - val_loss: 0.0157 - learning_rate: 1.0000e-05\n",
            "Epoch 32/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0455 - val_loss: 0.0158 - learning_rate: 1.0000e-05\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "CNN Performance (per target variable):\n",
            "\n",
            "Target: steady_state_temp_L0\n",
            "MSE: 0.02524318472379047\n",
            "MAE: 0.09745777152609301\n",
            "R²: 0.9737180055952138\n",
            "------------------------------\n",
            "\n",
            "Target: steady_state_temp_L1\n",
            "MSE: 0.025388434876355462\n",
            "MAE: 0.09808902270475205\n",
            "R²: 0.9735769336170158\n",
            "------------------------------\n",
            "\n",
            "Target: router_avg_temp_L0\n",
            "MSE: 0.02331115738701918\n",
            "MAE: 0.09055735560188723\n",
            "R²: 0.9766184638006357\n",
            "------------------------------\n",
            "\n",
            "Target: router_avg_temp_L1\n",
            "MSE: 0.01557867988039346\n",
            "MAE: 0.06882839962591349\n",
            "R²: 0.9851421300640967\n",
            "------------------------------\n",
            "\n",
            "Target: core_avg_temp_L0\n",
            "MSE: 0.02763259159427248\n",
            "MAE: 0.10963220745732039\n",
            "R²: 0.9719501265977609\n",
            "------------------------------\n",
            "\n",
            "Target: core_avg_temp_L1\n",
            "MSE: 0.021284793968151406\n",
            "MAE: 0.08975718125351562\n",
            "R²: 0.9789721144977938\n",
            "------------------------------\n",
            "\n",
            "Target: mem_avg_temp_L0\n",
            "MSE: 0.03487144512571244\n",
            "MAE: 0.11975766429836573\n",
            "R²: 0.96529471722681\n",
            "------------------------------\n",
            "\n",
            "Target: mem_avg_temp_L1\n",
            "MSE: 0.019534599745447512\n",
            "MAE: 0.08044440473579446\n",
            "R²: 0.9809956088826978\n",
            "------------------------------\n",
            "\n",
            "Target: total_area\n",
            "MSE: 0.004349301639089114\n",
            "MAE: 0.05043776888999041\n",
            "R²: 0.995746701542434\n",
            "------------------------------\n",
            "\n",
            "Target: avg_power\n",
            "MSE: 0.004476854875289679\n",
            "MAE: 0.04986262193559363\n",
            "R²: 0.9955195524956381\n",
            "------------------------------\n",
            "\n",
            "Target: avg_cores_power\n",
            "MSE: 0.004272910402279757\n",
            "MAE: 0.049713276498365065\n",
            "R²: 0.9957539250958729\n",
            "------------------------------\n",
            "\n",
            "Target: avg_routers_power\n",
            "MSE: 0.006572783032776472\n",
            "MAE: 0.05497332425111954\n",
            "R²: 0.993272562759724\n",
            "------------------------------\n",
            "\n",
            "Target: avg_power_per_router\n",
            "MSE: 0.01385876004392065\n",
            "MAE: 0.07946821760032936\n",
            "R²: 0.985832144311577\n",
            "------------------------------\n",
            "\n",
            "Target: layer_area\n",
            "MSE: 0.004225792488209651\n",
            "MAE: 0.049324989486230625\n",
            "R²: 0.9958674834482273\n",
            "------------------------------\n",
            "\n",
            "Target: area_per_core\n",
            "MSE: 7.73666184801724e-09\n",
            "MAE: 5.596590977210178e-05\n",
            "R²: 0.0\n",
            "------------------------------\n",
            "\n",
            "CNN Evaluation Results DataFrame:\n",
            "   algorithm                target           MSE       MAE        R²\n",
            "0        CNN  steady_state_temp_L0  2.524318e-02  0.097458  0.973718\n",
            "1        CNN  steady_state_temp_L1  2.538843e-02  0.098089  0.973577\n",
            "2        CNN    router_avg_temp_L0  2.331116e-02  0.090557  0.976618\n",
            "3        CNN    router_avg_temp_L1  1.557868e-02  0.068828  0.985142\n",
            "4        CNN      core_avg_temp_L0  2.763259e-02  0.109632  0.971950\n",
            "5        CNN      core_avg_temp_L1  2.128479e-02  0.089757  0.978972\n",
            "6        CNN       mem_avg_temp_L0  3.487145e-02  0.119758  0.965295\n",
            "7        CNN       mem_avg_temp_L1  1.953460e-02  0.080444  0.980996\n",
            "8        CNN            total_area  4.349302e-03  0.050438  0.995747\n",
            "9        CNN             avg_power  4.476855e-03  0.049863  0.995520\n",
            "10       CNN       avg_cores_power  4.272910e-03  0.049713  0.995754\n",
            "11       CNN     avg_routers_power  6.572783e-03  0.054973  0.993273\n",
            "12       CNN  avg_power_per_router  1.385876e-02  0.079468  0.985832\n",
            "13       CNN            layer_area  4.225792e-03  0.049325  0.995867\n",
            "14       CNN         area_per_core  7.736662e-09  0.000056  0.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "new_data = pd.DataFrame({\n",
        "    'dimx': [14],\n",
        "    'dimy': [11],\n",
        "    'dimz': [2],\n",
        "    'buffer_size': [10],\n",
        "    'packet_size_min': [4],\n",
        "    'packet_size_max': [8],\n",
        "    'routing_type_oe_3d': [1],  # Make sure to align with the encoded columns\n",
        "    'selection_strategy_thermal': [1],\n",
        "    'traffic_type_random': [1],\n",
        "    'injection_rate': [0.05]\n",
        "})\n",
        "\n",
        "# Ensure all columns are present (including any missing dummy variables from the training data)\n",
        "# Missing columns in new_data are filled with 0s\n",
        "for col in X.columns:\n",
        "    if col not in new_data:\n",
        "        new_data[col] = 0\n",
        "\n",
        "# Reorder the new_data columns to match the original feature order\n",
        "new_data = new_data[X.columns]\n",
        "\n",
        "# Scale the new data using the previously fitted scaler\n",
        "new_data_scaled = scaler_X.transform(new_data)\n",
        "\n",
        "# Reshape the scaled data to fit the CNN input shape\n",
        "new_data_cnn = new_data_scaled.reshape(1, new_data_scaled.shape[1], 1)  # Shape (1, num_features, 1)\n",
        "\n",
        "# Make predictions with the CNN model\n",
        "new_data_pred_scaled = cnn_model.predict(new_data_cnn)\n",
        "\n",
        "# Inverse scale the predictions to get original scale\n",
        "new_data_pred = scaler_y.inverse_transform(new_data_pred_scaled)\n",
        "\n",
        "# Convert the prediction to a DataFrame for readability\n",
        "predictions_df = pd.DataFrame(new_data_pred, columns=target_columns)\n",
        "\n",
        "# Display the predictions\n",
        "print(\"Predictions for the new data:\")\n",
        "print(predictions_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8RkYuAUPVyow",
        "outputId": "ba25dbef-bb7a-4c46-a164-f6a2aedb4f4f"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step\n",
            "Predictions for the new data:\n",
            "   steady_state_temp_L0  steady_state_temp_L1  router_avg_temp_L0  \\\n",
            "0            141.590027            140.825592           26.857075   \n",
            "\n",
            "   router_avg_temp_L1  core_avg_temp_L0  core_avg_temp_L1  mem_avg_temp_L0  \\\n",
            "0           26.589748         26.159397         25.996588        25.862862   \n",
            "\n",
            "   mem_avg_temp_L1   total_area     avg_power  avg_cores_power  \\\n",
            "0        25.731989  729290496.0  4.319029e-07     3.490335e-07   \n",
            "\n",
            "   avg_routers_power  avg_power_per_router   layer_area  area_per_core  \n",
            "0       8.383054e-08          2.812783e-10  365363648.0      4695230.0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "# Reshape the data to fit an RNN input (samples, time steps, features)\n",
        "X_train_rnn = X_train_scaled.reshape(X_train_scaled.shape[0], X_train_scaled.shape[1], 1)  # 1 channel for each time step\n",
        "X_test_rnn = X_test_scaled.reshape(X_test_scaled.shape[0], X_test_scaled.shape[1], 1)  # Same reshaping for test set\n",
        "\n",
        "# Build a deeper RNN model using multiple LSTM layers\n",
        "rnn_model = Sequential()\n",
        "\n",
        "# Add LSTM layers with more units and dropout for regularization\n",
        "rnn_model.add(LSTM(128, activation='relu', input_shape=(X_train_rnn.shape[1], 1), return_sequences=True))\n",
        "rnn_model.add(Dropout(0.2))  # Add dropout to prevent overfitting\n",
        "\n",
        "rnn_model.add(LSTM(256, activation='relu', return_sequences=True))  # Deeper layer\n",
        "rnn_model.add(Dropout(0.2))  # Add dropout to prevent overfitting\n",
        "\n",
        "rnn_model.add(LSTM(512, activation='relu', return_sequences=False))  # Even deeper LSTM layer\n",
        "rnn_model.add(Dropout(0.3))  # Higher dropout rate\n",
        "\n",
        "# Add dense layers for regression\n",
        "rnn_model.add(Dense(256, activation='relu'))  # Larger dense layer\n",
        "rnn_model.add(Dense(128, activation='relu'))  # Another dense layer\n",
        "rnn_model.add(Dense(64, activation='relu'))   # Another dense layer\n",
        "rnn_model.add(Dense(len(target_columns)))  # Output layer for all targets at once\n",
        "\n",
        "# Compile the RNN model\n",
        "rnn_model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Train the model\n",
        "rnn_model.fit(X_train_rnn, y_train_scaled, epochs=20, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Predict using the trained RNN model\n",
        "y_pred_rnn_scaled = rnn_model.predict(X_test_rnn)\n",
        "\n",
        "# Prepare a list to store the evaluation results\n",
        "rnn_evaluation_results = []\n",
        "\n",
        "# Evaluate the model for each target variable separately\n",
        "print(\"Deeper RNN (LSTM) Performance (per target variable):\")\n",
        "for i, target in enumerate(target_columns):\n",
        "    y_test_target = y_test_scaled[:, i]  # Get actual values for target i\n",
        "    y_pred_target = y_pred_rnn_scaled[:, i]  # Get predicted values for target i\n",
        "\n",
        "    # Calculate performance metrics\n",
        "    mse = mean_squared_error(y_test_target, y_pred_target)\n",
        "    mae = mean_absolute_error(y_test_target, y_pred_target)\n",
        "    r2 = r2_score(y_test_target, y_pred_target)\n",
        "\n",
        "    # Append results to the list\n",
        "    rnn_evaluation_results.append({\n",
        "        'algorithm': 'Deeper RNN (LSTM)',\n",
        "        'target': target,\n",
        "        'MSE': mse,\n",
        "        'MAE': mae,\n",
        "        'R²': r2\n",
        "    })\n",
        "\n",
        "    # Print results for the current target\n",
        "    print(f\"\\nTarget: {target}\")\n",
        "    print(\"MSE:\", mse)\n",
        "    print(\"MAE:\", mae)\n",
        "    print(\"R²:\", r2)\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "# Convert the results list to a DataFrame\n",
        "rnn_evaluation_df = pd.DataFrame(rnn_evaluation_results)\n",
        "\n",
        "# Display the RNN evaluation results DataFrame\n",
        "print(\"\\nDeeper RNN Evaluation Results DataFrame:\")\n",
        "print(rnn_evaluation_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hCs38spd_-Z",
        "outputId": "d98dd75d-f2bf-40e2-fce6-4013ee52ba99"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 12ms/step - loss: 0.6645 - val_loss: 0.5664\n",
            "Epoch 2/20\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - loss: 0.5028 - val_loss: 0.4097\n",
            "Epoch 3/20\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.3652 - val_loss: 0.3071\n",
            "Epoch 4/20\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.2490 - val_loss: 0.1026\n",
            "Epoch 5/20\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - loss: 0.1034 - val_loss: 0.0504\n",
            "Epoch 6/20\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0703 - val_loss: 0.0983\n",
            "Epoch 7/20\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0864 - val_loss: 0.0688\n",
            "Epoch 8/20\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - loss: 0.0663 - val_loss: 0.0313\n",
            "Epoch 9/20\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0487 - val_loss: 0.0272\n",
            "Epoch 10/20\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0400 - val_loss: 0.0256\n",
            "Epoch 11/20\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0424 - val_loss: 0.0534\n",
            "Epoch 12/20\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0551 - val_loss: 0.0180\n",
            "Epoch 13/20\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0316 - val_loss: 0.0185\n",
            "Epoch 14/20\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0309 - val_loss: 0.0922\n",
            "Epoch 15/20\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0415 - val_loss: 0.0141\n",
            "Epoch 16/20\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0341 - val_loss: 0.0190\n",
            "Epoch 17/20\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - loss: 0.0328 - val_loss: 0.0161\n",
            "Epoch 18/20\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0238 - val_loss: 0.0134\n",
            "Epoch 19/20\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - loss: 0.0261 - val_loss: 0.0144\n",
            "Epoch 20/20\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0243 - val_loss: 0.0145\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step\n",
            "Deeper RNN (LSTM) Performance (per target variable):\n",
            "\n",
            "Target: steady_state_temp_L0\n",
            "MSE: 0.018068839830149324\n",
            "MAE: 0.08126289865188807\n",
            "R²: 0.9811875897390472\n",
            "------------------------------\n",
            "\n",
            "Target: steady_state_temp_L1\n",
            "MSE: 0.01766832909145001\n",
            "MAE: 0.0800525616942383\n",
            "R²: 0.9816116497636261\n",
            "------------------------------\n",
            "\n",
            "Target: router_avg_temp_L0\n",
            "MSE: 0.022896850620749715\n",
            "MAE: 0.09402442586207033\n",
            "R²: 0.9770340214021885\n",
            "------------------------------\n",
            "\n",
            "Target: router_avg_temp_L1\n",
            "MSE: 0.015456613907882397\n",
            "MAE: 0.06532770039852967\n",
            "R²: 0.9852585481660856\n",
            "------------------------------\n",
            "\n",
            "Target: core_avg_temp_L0\n",
            "MSE: 0.039768176528913436\n",
            "MAE: 0.12693851049061408\n",
            "R²: 0.9596312812980912\n",
            "------------------------------\n",
            "\n",
            "Target: core_avg_temp_L1\n",
            "MSE: 0.022914964795090056\n",
            "MAE: 0.0896228632766653\n",
            "R²: 0.9773616199095354\n",
            "------------------------------\n",
            "\n",
            "Target: mem_avg_temp_L0\n",
            "MSE: 0.03229964109864727\n",
            "MAE: 0.11700791733353215\n",
            "R²: 0.9678542666138445\n",
            "------------------------------\n",
            "\n",
            "Target: mem_avg_temp_L1\n",
            "MSE: 0.01662288975958161\n",
            "MAE: 0.07741612451858772\n",
            "R²: 0.9838282891583429\n",
            "------------------------------\n",
            "\n",
            "Target: total_area\n",
            "MSE: 0.0023399125792219417\n",
            "MAE: 0.03541235326418089\n",
            "R²: 0.9977117368741231\n",
            "------------------------------\n",
            "\n",
            "Target: avg_power\n",
            "MSE: 0.0038799769676717876\n",
            "MAE: 0.042352006882259374\n",
            "R²: 0.9961169093915152\n",
            "------------------------------\n",
            "\n",
            "Target: avg_cores_power\n",
            "MSE: 0.0029711432264539596\n",
            "MAE: 0.03900372704552554\n",
            "R²: 0.9970475166800402\n",
            "------------------------------\n",
            "\n",
            "Target: avg_routers_power\n",
            "MSE: 0.007508394559296267\n",
            "MAE: 0.05040857127731262\n",
            "R²: 0.9923149367747259\n",
            "------------------------------\n",
            "\n",
            "Target: avg_power_per_router\n",
            "MSE: 0.019652956255071487\n",
            "MAE: 0.09470701571058943\n",
            "R²: 0.979908718587354\n",
            "------------------------------\n",
            "\n",
            "Target: layer_area\n",
            "MSE: 0.0024702542610824\n",
            "MAE: 0.037497478939668795\n",
            "R²: 0.9975842716722385\n",
            "------------------------------\n",
            "\n",
            "Target: area_per_core\n",
            "MSE: 1.9757073705458773e-05\n",
            "MAE: 0.0036110957539838904\n",
            "R²: 0.0\n",
            "------------------------------\n",
            "\n",
            "Deeper RNN Evaluation Results DataFrame:\n",
            "            algorithm                target       MSE       MAE        R²\n",
            "0   Deeper RNN (LSTM)  steady_state_temp_L0  0.018069  0.081263  0.981188\n",
            "1   Deeper RNN (LSTM)  steady_state_temp_L1  0.017668  0.080053  0.981612\n",
            "2   Deeper RNN (LSTM)    router_avg_temp_L0  0.022897  0.094024  0.977034\n",
            "3   Deeper RNN (LSTM)    router_avg_temp_L1  0.015457  0.065328  0.985259\n",
            "4   Deeper RNN (LSTM)      core_avg_temp_L0  0.039768  0.126939  0.959631\n",
            "5   Deeper RNN (LSTM)      core_avg_temp_L1  0.022915  0.089623  0.977362\n",
            "6   Deeper RNN (LSTM)       mem_avg_temp_L0  0.032300  0.117008  0.967854\n",
            "7   Deeper RNN (LSTM)       mem_avg_temp_L1  0.016623  0.077416  0.983828\n",
            "8   Deeper RNN (LSTM)            total_area  0.002340  0.035412  0.997712\n",
            "9   Deeper RNN (LSTM)             avg_power  0.003880  0.042352  0.996117\n",
            "10  Deeper RNN (LSTM)       avg_cores_power  0.002971  0.039004  0.997048\n",
            "11  Deeper RNN (LSTM)     avg_routers_power  0.007508  0.050409  0.992315\n",
            "12  Deeper RNN (LSTM)  avg_power_per_router  0.019653  0.094707  0.979909\n",
            "13  Deeper RNN (LSTM)            layer_area  0.002470  0.037497  0.997584\n",
            "14  Deeper RNN (LSTM)         area_per_core  0.000020  0.003611  0.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "new_data = pd.DataFrame({\n",
        "    'dimx': [3],\n",
        "    'dimy': [10],\n",
        "    'dimz': [2],\n",
        "    'buffer_size': [8],\n",
        "    'packet_size_min': [4],\n",
        "    'packet_size_max': [8],\n",
        "    'routing_type_fullyadaptive': [1],    # Make sure to align with the encoded columns\n",
        "    'selection_strategy_thermal': [1],\n",
        "    'traffic_type_random': [1],\n",
        "    'injection_rate': [0.06]\n",
        "})\n",
        "\n",
        "# Ensure all columns are present (including any missing dummy variables from the training data)\n",
        "# Missing columns in new_data are filled with 0s\n",
        "for col in X.columns:\n",
        "    if col not in new_data:\n",
        "        new_data[col] = 0\n",
        "\n",
        "# Reorder the new_data columns to match the original feature order\n",
        "new_data = new_data[X.columns]\n",
        "\n",
        "# Scale the new data using the previously fitted scaler\n",
        "new_data_scaled = scaler_X.transform(new_data)\n",
        "\n",
        "# Reshape the scaled data to fit the CNN input shape\n",
        "new_data_cnn = new_data_scaled.reshape(1, new_data_scaled.shape[1], 1)  # Shape (1, num_features, 1)\n",
        "\n",
        "# Make predictions with the CNN model\n",
        "new_data_pred_scaled = rnn_model.predict(new_data_cnn)\n",
        "\n",
        "# Inverse scale the predictions to get original scale\n",
        "new_data_pred = scaler_y.inverse_transform(new_data_pred_scaled)\n",
        "\n",
        "# Convert the prediction to a DataFrame for readability\n",
        "predictions_df = pd.DataFrame(new_data_pred, columns=target_columns)\n",
        "\n",
        "# Display the predictions\n",
        "print(\"Predictions for the new data:\")\n",
        "print(predictions_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQRK2scRe3Go",
        "outputId": "15745ecf-e0fa-41cb-cf9b-c6d0b39db19d"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "Predictions for the new data:\n",
            "   steady_state_temp_L0  steady_state_temp_L1  router_avg_temp_L0  \\\n",
            "0             67.197083             67.573349           25.606779   \n",
            "\n",
            "   router_avg_temp_L1  core_avg_temp_L0  core_avg_temp_L1  mem_avg_temp_L0  \\\n",
            "0           25.979721         25.475954         25.574236         25.37184   \n",
            "\n",
            "   mem_avg_temp_L1   total_area     avg_power  avg_cores_power  \\\n",
            "0        25.447403  160086704.0  8.112868e-08     7.021715e-08   \n",
            "\n",
            "   avg_routers_power  avg_power_per_router  layer_area  area_per_core  \n",
            "0       1.132547e-08          1.961568e-10  75313344.0      4695230.0  \n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}