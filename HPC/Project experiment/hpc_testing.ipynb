{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMO0upDLyDWE",
        "outputId": "b838fd18-dd84-4ca0-fc45-704b76b2ce2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error for each output: [1.69970462e+01 1.62926494e+01 7.83984046e-02 4.69594195e-02\n",
            " 9.46624266e-03 5.45474934e-03 7.23712576e-04 6.25039666e-04\n",
            " 1.17421161e+08 5.86692293e-16 1.67889097e-16 1.28354052e-16\n",
            " 3.16472000e-21 2.93687462e+07 0.00000000e+00]\n",
            "Weighted R2 Score: 0.9999999978381127\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Load the dataset\n",
        "# Replace 'your_file.csv' with the path to your actual dataset\n",
        "data = pd.read_csv('pat_dataset.csv')\n",
        "\n",
        "# Define input (X) and output (y) columns\n",
        "input_columns = ['dimx', 'dimy', 'dimz', 'buffer_size', 'packet_size_min', 'packet_size_max',\n",
        "                 'routing_type', 'selection_strategy', 'traffic_type', 'injection_rate']\n",
        "output_columns = ['steady_state_temp_L0', 'steady_state_temp_L1', 'router_avg_temp_L0', 'router_avg_temp_L1',\n",
        "                  'core_avg_temp_L0', 'core_avg_temp_L1', 'mem_avg_temp_L0', 'mem_avg_temp_L1',\n",
        "                  'total_area', 'avg_power', 'avg_cores_power', 'avg_routers_power',\n",
        "                  'avg_power_per_router', 'layer_area', 'area_per_core']\n",
        "\n",
        "X = data[input_columns]\n",
        "y = data[output_columns]\n",
        "\n",
        "# Preprocessing pipeline\n",
        "# OneHotEncode categorical columns and Standardize numerical columns\n",
        "categorical_cols = ['routing_type', 'selection_strategy', 'traffic_type']\n",
        "numerical_cols = [col for col in input_columns if col not in categorical_cols]\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numerical_cols),\n",
        "        ('cat', OneHotEncoder(), categorical_cols)\n",
        "    ])\n",
        "\n",
        "# Create the pipeline with preprocessing and model\n",
        "model = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('regressor', RandomForestRegressor(n_estimators=100, random_state=42))\n",
        "])\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "mse = mean_squared_error(y_test, y_pred, multioutput='raw_values')\n",
        "r2 = r2_score(y_test, y_pred, multioutput='variance_weighted')\n",
        "\n",
        "# Display results\n",
        "print(\"Mean Squared Error for each output:\", mse)\n",
        "print(\"Weighted R2 Score:\", r2)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import Dense, Input, Concatenate, BatchNormalization, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.layers import Embedding, Flatten\n",
        "\n",
        "# Load dataset\n",
        "data = pd.read_csv('pat_dataset.csv')\n",
        "\n",
        "# Separate inputs and outputs\n",
        "input_columns = ['dimx', 'dimy', 'dimz', 'buffer_size', 'packet_size_min',\n",
        "                 'packet_size_max', 'routing_type', 'selection_strategy',\n",
        "                 'traffic_type', 'injection_rate']\n",
        "output_columns = ['steady_state_temp_L0', 'steady_state_temp_L1',\n",
        "                  'router_avg_temp_L0', 'router_avg_temp_L1',\n",
        "                  'core_avg_temp_L0', 'core_avg_temp_L1',\n",
        "                  'mem_avg_temp_L0', 'mem_avg_temp_L1',\n",
        "                  'total_area', 'avg_power', 'avg_cores_power',\n",
        "                  'avg_routers_power', 'avg_power_per_router',\n",
        "                  'layer_area', 'area_per_core']\n",
        "\n",
        "X = data[input_columns]\n",
        "y = data[output_columns]\n",
        "\n",
        "# One-hot encode categorical features\n",
        "categorical_features = ['routing_type', 'selection_strategy', 'traffic_type']\n",
        "X = pd.get_dummies(X, columns=categorical_features, drop_first=True)\n",
        "\n",
        "# Scale numerical features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define neural network model\n",
        "input_shape = X_train.shape[1]\n",
        "model = Sequential([\n",
        "    Dense(128, activation='relu', input_shape=(input_shape,)),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.3),\n",
        "    Dense(64, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.3),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(y_train.shape[1])  # Output layer with number of outputs equal to the target variables\n",
        "])\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mae'])\n",
        "\n",
        "# Early stopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "# Train model\n",
        "history = model.fit(X_train, y_train, validation_data=(X_test, y_test),\n",
        "                    epochs=100, batch_size=32, callbacks=[early_stopping], verbose=1)\n",
        "\n",
        "# Evaluate model\n",
        "results = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Test Loss (MSE): {results[0]}\")\n",
        "print(f\"Test Mean Absolute Error: {results[1]}\")\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate individual metrics for each output variable\n",
        "mse_per_output = np.mean((y_test - y_pred) ** 2, axis=0)\n",
        "mae_per_output = np.mean(np.abs(y_test - y_pred), axis=0)\n",
        "\n",
        "# Display results for each output\n",
        "print(\"Performance Metrics for Each Output:\")\n",
        "for i, col in enumerate(output_columns):\n",
        "    print(f\"Output: {col}\")\n",
        "    print(f\" - MSE: {mse_per_output[i]:.4f}\")\n",
        "    print(f\" - MAE: {mae_per_output[i]:.4f}\")\n",
        "    print(\"\")\n",
        "\n",
        "# Overall performance metrics\n",
        "overall_mse = np.mean(mse_per_output)\n",
        "overall_mae = np.mean(mae_per_output)\n",
        "\n",
        "print(\"Overall Metrics:\")\n",
        "print(f\" - Mean MSE across outputs: {overall_mse:.4f}\")\n",
        "print(f\" - Mean MAE across outputs: {overall_mae:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWkFbYKGy553",
        "outputId": "fd37f129-d5fb-4590-d83b-fb88f4f23363"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 12801769574760448.0000 - mae: 32131790.0000 - val_loss: 13373534948556800.0000 - val_mae: 32893030.0000\n",
            "Epoch 2/100\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 13203551954141184.0000 - mae: 32655716.0000 - val_loss: 13372308735393792.0000 - val_mae: 32890766.0000\n",
            "Epoch 3/100\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 13047841136050176.0000 - mae: 32443174.0000 - val_loss: 13369505195491328.0000 - val_mae: 32885602.0000\n",
            "Epoch 4/100\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 12803391998656512.0000 - mae: 32098520.0000 - val_loss: 13364890253131776.0000 - val_mae: 32877002.0000\n",
            "Epoch 5/100\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 13028339837042688.0000 - mae: 32319528.0000 - val_loss: 13358051591454720.0000 - val_mae: 32864250.0000\n",
            "Epoch 6/100\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 13643246009843712.0000 - mae: 33187998.0000 - val_loss: 13347869297737728.0000 - val_mae: 32844696.0000\n",
            "Epoch 7/100\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 13111241295790080.0000 - mae: 32407604.0000 - val_loss: 13336891361329152.0000 - val_mae: 32824258.0000\n",
            "Epoch 8/100\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 13176231667171328.0000 - mae: 32686404.0000 - val_loss: 13322171434663936.0000 - val_mae: 32796752.0000\n",
            "Epoch 9/100\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 12940911482765312.0000 - mae: 32281380.0000 - val_loss: 13305901024804864.0000 - val_mae: 32766292.0000\n",
            "Epoch 10/100\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 13012275585613824.0000 - mae: 32378130.0000 - val_loss: 13286766945501184.0000 - val_mae: 32730774.0000\n",
            "Epoch 11/100\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 12972398961754112.0000 - mae: 32314092.0000 - val_loss: 13263650357772288.0000 - val_mae: 32687124.0000\n",
            "Epoch 12/100\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 13195244413648896.0000 - mae: 32447254.0000 - val_loss: 13237554136481792.0000 - val_mae: 32638288.0000\n",
            "Epoch 13/100\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 13183350575464448.0000 - mae: 32493248.0000 - val_loss: 13203691540578304.0000 - val_mae: 32576564.0000\n",
            "Epoch 14/100\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 13202337552138240.0000 - mae: 32445270.0000 - val_loss: 13173389472563200.0000 - val_mae: 32525398.0000\n",
            "Epoch 15/100\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 12952122421149696.0000 - mae: 32138914.0000 - val_loss: 13141615304507392.0000 - val_mae: 32479916.0000\n",
            "Epoch 16/100\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 13017402702823424.0000 - mae: 32258958.0000 - val_loss: 13097440492126208.0000 - val_mae: 32411786.0000\n",
            "Epoch 17/100\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 12766799951036416.0000 - mae: 31867562.0000 - val_loss: 13065004899106816.0000 - val_mae: 32369952.0000\n",
            "Epoch 18/100\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 12717928591917056.0000 - mae: 31898010.0000 - val_loss: 13013990351306752.0000 - val_mae: 32304552.0000\n",
            "Epoch 19/100\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 12719816230043648.0000 - mae: 31902438.0000 - val_loss: 12968800852901888.0000 - val_mae: 32250612.0000\n",
            "Epoch 20/100\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 12816057857212416.0000 - mae: 32027794.0000 - val_loss: 12903908192026624.0000 - val_mae: 32156726.0000\n",
            "Epoch 21/100\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 12825176072781824.0000 - mae: 31997958.0000 - val_loss: 12849850659897344.0000 - val_mae: 32090706.0000\n",
            "Epoch 22/100\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 12632303050162176.0000 - mae: 31787222.0000 - val_loss: 12794700058591232.0000 - val_mae: 32021778.0000\n",
            "Epoch 23/100\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 12439672693194752.0000 - mae: 31518196.0000 - val_loss: 12728394353475584.0000 - val_mae: 31936422.0000\n",
            "Epoch 24/100\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 12531462586761216.0000 - mae: 31516326.0000 - val_loss: 12645273851396096.0000 - val_mae: 31827098.0000\n",
            "Epoch 25/100\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 12433913142050816.0000 - mae: 31498752.0000 - val_loss: 12572027479130112.0000 - val_mae: 31736438.0000\n",
            "Epoch 26/100\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 12261520670982144.0000 - mae: 31212554.0000 - val_loss: 12488369032396800.0000 - val_mae: 31616096.0000\n",
            "Epoch 27/100\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 12220146177277952.0000 - mae: 31270960.0000 - val_loss: 12406106450034688.0000 - val_mae: 31492854.0000\n",
            "Epoch 28/100\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 12037310493229056.0000 - mae: 30983362.0000 - val_loss: 12307768878825472.0000 - val_mae: 31374912.0000\n",
            "Epoch 29/100\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 12254689525497856.0000 - mae: 31212952.0000 - val_loss: 12226382469791744.0000 - val_mae: 31276598.0000\n",
            "Epoch 30/100\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 11975368474886144.0000 - mae: 30851416.0000 - val_loss: 12114146384412672.0000 - val_mae: 31113494.0000\n",
            "Epoch 31/100\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 11855065367183360.0000 - mae: 30656768.0000 - val_loss: 12014860699172864.0000 - val_mae: 30988456.0000\n",
            "Epoch 32/100\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 11940942164525056.0000 - mae: 30852536.0000 - val_loss: 11886859936333824.0000 - val_mae: 30790144.0000\n",
            "Epoch 33/100\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 11538484401537024.0000 - mae: 30320598.0000 - val_loss: 11793178109673472.0000 - val_mae: 30674634.0000\n",
            "Epoch 34/100\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 11747956399013888.0000 - mae: 30540358.0000 - val_loss: 11641112645074944.0000 - val_mae: 30479862.0000\n",
            "Epoch 35/100\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 11501035507941376.0000 - mae: 30222148.0000 - val_loss: 11576213541748736.0000 - val_mae: 30394090.0000\n",
            "Epoch 36/100\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 11263696688906240.0000 - mae: 29810980.0000 - val_loss: 11419468710281216.0000 - val_mae: 30164440.0000\n",
            "Epoch 37/100\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 11076239620046848.0000 - mae: 29562136.0000 - val_loss: 11305806695759872.0000 - val_mae: 29994060.0000\n",
            "Epoch 38/100\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 11286274258239488.0000 - mae: 29849290.0000 - val_loss: 11128730562854912.0000 - val_mae: 29760960.0000\n",
            "Epoch 39/100\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 11020612277370880.0000 - mae: 29553900.0000 - val_loss: 11057458801803264.0000 - val_mae: 29660486.0000\n",
            "Epoch 40/100\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 10679991306027008.0000 - mae: 29027926.0000 - val_loss: 10864955146371072.0000 - val_mae: 29357200.0000\n",
            "Epoch 41/100\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 10696369090068480.0000 - mae: 29125334.0000 - val_loss: 10622760866807808.0000 - val_mae: 29010836.0000\n",
            "Epoch 42/100\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 10261775308029952.0000 - mae: 28504424.0000 - val_loss: 10598961379278848.0000 - val_mae: 29004256.0000\n",
            "Epoch 43/100\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 10389587092307968.0000 - mae: 28665680.0000 - val_loss: 10364812647202816.0000 - val_mae: 28637192.0000\n",
            "Epoch 44/100\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 10024901419204608.0000 - mae: 28054544.0000 - val_loss: 10270663742849024.0000 - val_mae: 28533722.0000\n",
            "Epoch 45/100\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 10106715177484288.0000 - mae: 28265886.0000 - val_loss: 9994978382053376.0000 - val_mae: 28084520.0000\n",
            "Epoch 46/100\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 9966561804681216.0000 - mae: 27925840.0000 - val_loss: 9829631804833792.0000 - val_mae: 27810086.0000\n",
            "Epoch 47/100\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 9681148342960128.0000 - mae: 27481702.0000 - val_loss: 9675454290067456.0000 - val_mae: 27634374.0000\n",
            "Epoch 48/100\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 9523686251954176.0000 - mae: 27165958.0000 - val_loss: 9451243038572544.0000 - val_mae: 27232790.0000\n",
            "Epoch 49/100\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 9303467172560896.0000 - mae: 26906064.0000 - val_loss: 9328080556392448.0000 - val_mae: 27061646.0000\n",
            "Epoch 50/100\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 9145227692474368.0000 - mae: 26656452.0000 - val_loss: 9123316916813824.0000 - val_mae: 26755060.0000\n",
            "Epoch 51/100\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 8847925224407040.0000 - mae: 26124674.0000 - val_loss: 8875587498147840.0000 - val_mae: 26325788.0000\n",
            "Epoch 52/100\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 8817561953107968.0000 - mae: 26107612.0000 - val_loss: 8719547578187776.0000 - val_mae: 26076758.0000\n",
            "Epoch 53/100\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 8713726286888960.0000 - mae: 25958952.0000 - val_loss: 8481982736498688.0000 - val_mae: 25676408.0000\n",
            "Epoch 54/100\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 8470207546785792.0000 - mae: 25422674.0000 - val_loss: 8243400524431360.0000 - val_mae: 25277922.0000\n",
            "Epoch 55/100\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 8327873941209088.0000 - mae: 25304372.0000 - val_loss: 8089547279695872.0000 - val_mae: 25015180.0000\n",
            "Epoch 56/100\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 7848481502789632.0000 - mae: 24541346.0000 - val_loss: 7894669044219904.0000 - val_mae: 24699538.0000\n",
            "Epoch 57/100\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 7811186691145728.0000 - mae: 24432564.0000 - val_loss: 7646632535392256.0000 - val_mae: 24264814.0000\n",
            "Epoch 58/100\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 7580480912228352.0000 - mae: 23938554.0000 - val_loss: 7403072993099776.0000 - val_mae: 23820258.0000\n",
            "Epoch 59/100\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 7274341012078592.0000 - mae: 23366890.0000 - val_loss: 7201387771330560.0000 - val_mae: 23492364.0000\n",
            "Epoch 60/100\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 7075936608452608.0000 - mae: 22989054.0000 - val_loss: 6930815569100800.0000 - val_mae: 22941174.0000\n",
            "Epoch 61/100\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 7076805802459136.0000 - mae: 22941914.0000 - val_loss: 6686413139476480.0000 - val_mae: 22498924.0000\n",
            "Epoch 62/100\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 6714216073396224.0000 - mae: 22317268.0000 - val_loss: 6455184448290816.0000 - val_mae: 21992888.0000\n",
            "Epoch 63/100\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 6583115417911296.0000 - mae: 21982250.0000 - val_loss: 6272555996413952.0000 - val_mae: 21733422.0000\n",
            "Epoch 64/100\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 6130374325305344.0000 - mae: 21246408.0000 - val_loss: 6116740488495104.0000 - val_mae: 21312086.0000\n",
            "Epoch 65/100\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 5974707530629120.0000 - mae: 20849992.0000 - val_loss: 5855102891982848.0000 - val_mae: 20739878.0000\n",
            "Epoch 66/100\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 5933800651489280.0000 - mae: 20771524.0000 - val_loss: 5699811906945024.0000 - val_mae: 20528650.0000\n",
            "Epoch 67/100\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 5477259049697280.0000 - mae: 19677432.0000 - val_loss: 5401259066523648.0000 - val_mae: 19780312.0000\n",
            "Epoch 68/100\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5505161304735744.0000 - mae: 19743642.0000 - val_loss: 5296911225454592.0000 - val_mae: 19608464.0000\n",
            "Epoch 69/100\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 5278327438835712.0000 - mae: 19244864.0000 - val_loss: 5001265004150784.0000 - val_mae: 18858916.0000\n",
            "Epoch 70/100\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 5021305321553920.0000 - mae: 18706060.0000 - val_loss: 4657711643885568.0000 - val_mae: 18018696.0000\n",
            "Epoch 71/100\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 4773544764375040.0000 - mae: 17990078.0000 - val_loss: 4648225671741440.0000 - val_mae: 18203918.0000\n",
            "Epoch 72/100\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4576510992187392.0000 - mae: 17497420.0000 - val_loss: 4316522126245888.0000 - val_mae: 17174190.0000\n",
            "Epoch 73/100\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 4387168164249600.0000 - mae: 17030368.0000 - val_loss: 4150629014437888.0000 - val_mae: 16672443.0000\n",
            "Epoch 74/100\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 4271715685236736.0000 - mae: 16679412.0000 - val_loss: 3838470791364608.0000 - val_mae: 15937520.0000\n",
            "Epoch 75/100\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 3927601563303936.0000 - mae: 15824638.0000 - val_loss: 3827331525246976.0000 - val_mae: 15990268.0000\n",
            "Epoch 76/100\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 3662506249682944.0000 - mae: 15232164.0000 - val_loss: 3578626343698432.0000 - val_mae: 15165564.0000\n",
            "Epoch 77/100\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 3669114056867840.0000 - mae: 15152588.0000 - val_loss: 3327468467388416.0000 - val_mae: 14400164.0000\n",
            "Epoch 78/100\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 3487443651133440.0000 - mae: 14656764.0000 - val_loss: 3256786190598144.0000 - val_mae: 14345644.0000\n",
            "Epoch 79/100\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 3343641435176960.0000 - mae: 14361341.0000 - val_loss: 3012529521426432.0000 - val_mae: 13480169.0000\n",
            "Epoch 80/100\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 3058623915753472.0000 - mae: 13634396.0000 - val_loss: 2853009872650240.0000 - val_mae: 13054101.0000\n",
            "Epoch 81/100\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 2939956922155008.0000 - mae: 13400768.0000 - val_loss: 2582350697332736.0000 - val_mae: 11971683.0000\n",
            "Epoch 82/100\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 2767167435046912.0000 - mae: 12956515.0000 - val_loss: 2564979970539520.0000 - val_mae: 12110738.0000\n",
            "Epoch 83/100\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 2742862215118848.0000 - mae: 12849097.0000 - val_loss: 2251466953719808.0000 - val_mae: 11060771.0000\n",
            "Epoch 84/100\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 2497947879079936.0000 - mae: 12263454.0000 - val_loss: 2145307978629120.0000 - val_mae: 10775715.0000\n",
            "Epoch 85/100\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 2332181737242624.0000 - mae: 11958726.0000 - val_loss: 1953964501237760.0000 - val_mae: 10529839.0000\n",
            "Epoch 86/100\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 2237018146865152.0000 - mae: 11736736.0000 - val_loss: 1832790857351168.0000 - val_mae: 10429180.0000\n",
            "Epoch 87/100\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 2045387980406784.0000 - mae: 11284162.0000 - val_loss: 1790708365131776.0000 - val_mae: 10231855.0000\n",
            "Epoch 88/100\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 1925267543031808.0000 - mae: 10948588.0000 - val_loss: 1649072825958400.0000 - val_mae: 10039743.0000\n",
            "Epoch 89/100\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 1852360338964480.0000 - mae: 10821220.0000 - val_loss: 1527763622166528.0000 - val_mae: 9756621.0000\n",
            "Epoch 90/100\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 1720912596434944.0000 - mae: 10530831.0000 - val_loss: 1430076201631744.0000 - val_mae: 9508309.0000\n",
            "Epoch 91/100\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 1572719447506944.0000 - mae: 10075402.0000 - val_loss: 1243163251441664.0000 - val_mae: 9111404.0000\n",
            "Epoch 92/100\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 1492816681238528.0000 - mae: 9803933.0000 - val_loss: 1141749275688960.0000 - val_mae: 8855022.0000\n",
            "Epoch 93/100\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 1412776878669824.0000 - mae: 9553320.0000 - val_loss: 1033570055356416.0000 - val_mae: 8528355.0000\n",
            "Epoch 94/100\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 1311299417931776.0000 - mae: 9251096.0000 - val_loss: 957417533734912.0000 - val_mae: 8244733.5000\n",
            "Epoch 95/100\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 1235970791833600.0000 - mae: 9000080.0000 - val_loss: 859200892698624.0000 - val_mae: 7966042.5000\n",
            "Epoch 96/100\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 1103328847069184.0000 - mae: 8605289.0000 - val_loss: 716772260970496.0000 - val_mae: 7495338.5000\n",
            "Epoch 97/100\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 1062480755294208.0000 - mae: 8437009.0000 - val_loss: 676937781477376.0000 - val_mae: 7428136.0000\n",
            "Epoch 98/100\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 970797430603776.0000 - mae: 8113179.5000 - val_loss: 606673995563008.0000 - val_mae: 6976626.0000\n",
            "Epoch 99/100\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 908457322479616.0000 - mae: 7870652.0000 - val_loss: 592703003820032.0000 - val_mae: 6887454.5000\n",
            "Epoch 100/100\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 847633069375488.0000 - mae: 7636706.5000 - val_loss: 462401346469888.0000 - val_mae: 6293332.5000\n",
            "Test Loss (MSE): 462401346469888.0\n",
            "Test Mean Absolute Error: 6293332.5\n",
            "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "Performance Metrics for Each Output:\n",
            "Output: steady_state_temp_L0\n",
            " - MSE: 86866.9449\n",
            " - MAE: 246.4682\n",
            "\n",
            "Output: steady_state_temp_L1\n",
            " - MSE: 5877.5918\n",
            " - MAE: 56.8981\n",
            "\n",
            "Output: router_avg_temp_L0\n",
            " - MSE: 457.7469\n",
            " - MAE: 16.5953\n",
            "\n",
            "Output: router_avg_temp_L1\n",
            " - MSE: 100885.7140\n",
            " - MAE: 252.8370\n",
            "\n",
            "Output: core_avg_temp_L0\n",
            " - MSE: 256953.9788\n",
            " - MAE: 428.9234\n",
            "\n",
            "Output: core_avg_temp_L1\n",
            " - MSE: 2586.3129\n",
            " - MAE: 46.9465\n",
            "\n",
            "Output: mem_avg_temp_L0\n",
            " - MSE: 105.5013\n",
            " - MAE: 8.3183\n",
            "\n",
            "Output: mem_avg_temp_L1\n",
            " - MSE: 80754.7914\n",
            " - MAE: 226.8078\n",
            "\n",
            "Output: total_area\n",
            " - MSE: 6002032696079613.0000\n",
            " - MAE: 67200067.5138\n",
            "\n",
            "Output: avg_power\n",
            " - MSE: 76150.2232\n",
            " - MAE: 221.6785\n",
            "\n",
            "Output: avg_cores_power\n",
            " - MSE: 5655.0564\n",
            " - MAE: 61.0068\n",
            "\n",
            "Output: avg_routers_power\n",
            " - MSE: 17031.9953\n",
            " - MAE: 103.0666\n",
            "\n",
            "Output: avg_power_per_router\n",
            " - MSE: 28194.3583\n",
            " - MAE: 143.1380\n",
            "\n",
            "Output: layer_area\n",
            " - MSE: 927837480986918.6250\n",
            " - MAE: 25054978.4711\n",
            "\n",
            "Output: area_per_core\n",
            " - MSE: 6150862195017.7695\n",
            " - MAE: 2143147.5569\n",
            "\n",
            "Overall Metrics:\n",
            " - Mean MSE across outputs: 462401402661538.0000\n",
            " - Mean MAE across outputs: 6293333.7484\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-c663460f4432>:80: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  print(f\" - MSE: {mse_per_output[i]:.4f}\")\n",
            "<ipython-input-4-c663460f4432>:81: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  print(f\" - MAE: {mae_per_output[i]:.4f}\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "# Load your dataset\n",
        "df = pd.read_csv('pat_dataset.csv')  # Replace with your actual dataset path\n",
        "\n",
        "# Display the first few rows of the dataset (optional, to inspect data)\n",
        "print(df.head())\n",
        "\n",
        "# Identify non-numeric columns (categorical columns)\n",
        "categorical_columns = df.select_dtypes(include=['object']).columns\n",
        "print(\"Categorical columns:\", categorical_columns)\n",
        "\n",
        "# Convert categorical columns to numerical using one-hot encoding\n",
        "df = pd.get_dummies(df, columns=categorical_columns, drop_first=True)\n",
        "\n",
        "# Define the target columns (output variables)\n",
        "target_columns = [\n",
        "    'steady_state_temp_L0', 'steady_state_temp_L1', 'router_avg_temp_L0',\n",
        "    'router_avg_temp_L1', 'core_avg_temp_L0', 'core_avg_temp_L1',\n",
        "    'mem_avg_temp_L0', 'mem_avg_temp_L1', 'total_area', 'avg_power',\n",
        "    'avg_cores_power', 'avg_routers_power', 'avg_power_per_router',\n",
        "    'layer_area', 'area_per_core'\n",
        "]\n",
        "\n",
        "# Initialize dictionary to store the results\n",
        "results = {}\n",
        "\n",
        "# Split dataset into X (features) and y (target variables)\n",
        "X = df.drop(columns=target_columns)  # Drop target columns to get features\n",
        "\n",
        "# Iterate over each target and perform regression\n",
        "for target in target_columns:\n",
        "    # Extract the current target variable\n",
        "    y = df[target]\n",
        "\n",
        "    # Split the data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Train a Linear Regression model (you can replace this with other regression models)\n",
        "    model = LinearRegression()  # Example model, replace with other models as needed\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions on the test set\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Calculate performance metrics\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    # Store the metrics for this target variable\n",
        "    results[target] = {\n",
        "        'MSE': mse,\n",
        "        'MAE': mae,\n",
        "        'R²': r2\n",
        "    }\n",
        "\n",
        "# Output the results for each target variable\n",
        "for target, metrics in results.items():\n",
        "    print(f\"Results for {target}:\")\n",
        "    print(f\"  MSE: {metrics['MSE']}\")\n",
        "    print(f\"  MAE: {metrics['MAE']}\")\n",
        "    print(f\"  R²: {metrics['R²']}\")\n",
        "    print(\"-\" * 40)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nlH5pNaq1TjL",
        "outputId": "30969670-078b-4ce0-edc5-61ea480f57cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   dimx  dimy  dimz  buffer_size  packet_size_min  packet_size_max  \\\n",
            "0     3     2     2            4                4                8   \n",
            "1     3     2     2            4                4                8   \n",
            "2     3     2     2            4                4                8   \n",
            "3     3     2     2            4                4                8   \n",
            "4     3     2     2            4                4                8   \n",
            "\n",
            "  routing_type selection_strategy traffic_type  injection_rate  ...  \\\n",
            "0          xyz            thermal       random            0.01  ...   \n",
            "1          xyz            thermal       random            0.02  ...   \n",
            "2          xyz            thermal       random            0.03  ...   \n",
            "3          xyz            thermal       random            0.04  ...   \n",
            "4          xyz            thermal       random            0.05  ...   \n",
            "\n",
            "   core_avg_temp_L1  mem_avg_temp_L0  mem_avg_temp_L1  total_area  \\\n",
            "0         25.888400        25.666300        25.595383  28332600.0   \n",
            "1         26.080133        25.713567        25.636667  28332600.0   \n",
            "2         26.267683        25.756733        25.675050  28332600.0   \n",
            "3         26.387300        25.756150        25.676867  28332600.0   \n",
            "4         26.643717        25.839467        25.749517  28332600.0   \n",
            "\n",
            "      avg_power  avg_cores_power  avg_routers_power  avg_power_per_router  \\\n",
            "0  1.739630e-08     1.466710e-08       2.729280e-09          2.274400e-10   \n",
            "1  2.002180e-08     1.671670e-08       3.305090e-09          2.754240e-10   \n",
            "2  2.264300e-08     1.876560e-08       3.877400e-09          3.231170e-10   \n",
            "3  2.522700e-08     2.077950e-08       4.447460e-09          3.706220e-10   \n",
            "4  2.784280e-08     2.282540e-08       5.017420e-09          4.181190e-10   \n",
            "\n",
            "   layer_area  area_per_core  \n",
            "0  14166300.0      4695230.0  \n",
            "1  14166300.0      4695230.0  \n",
            "2  14166300.0      4695230.0  \n",
            "3  14166300.0      4695230.0  \n",
            "4  14166300.0      4695230.0  \n",
            "\n",
            "[5 rows x 25 columns]\n",
            "Categorical columns: Index(['routing_type', 'selection_strategy', 'traffic_type'], dtype='object')\n",
            "Results for steady_state_temp_L0:\n",
            "  MSE: 320.02247626791046\n",
            "  MAE: 13.50134153543086\n",
            "  R²: 0.5100783891806184\n",
            "----------------------------------------\n",
            "Results for steady_state_temp_L1:\n",
            "  MSE: 318.75669049216606\n",
            "  MAE: 13.469048271804237\n",
            "  R²: 0.506225630681085\n",
            "----------------------------------------\n",
            "Results for router_avg_temp_L0:\n",
            "  MSE: 0.6752001459390686\n",
            "  MAE: 0.4819751192748584\n",
            "  R²: 0.3250407966488047\n",
            "----------------------------------------\n",
            "Results for router_avg_temp_L1:\n",
            "  MSE: 3.028050185408971\n",
            "  MAE: 1.1244143037665901\n",
            "  R²: 0.1345225660455277\n",
            "----------------------------------------\n",
            "Results for core_avg_temp_L0:\n",
            "  MSE: 0.10009149472502951\n",
            "  MAE: 0.20781143659669807\n",
            "  R²: 0.3337650427236797\n",
            "----------------------------------------\n",
            "Results for core_avg_temp_L1:\n",
            "  MSE: 0.3333732665071357\n",
            "  MAE: 0.3909396332424837\n",
            "  R²: 0.08832369386021721\n",
            "----------------------------------------\n",
            "Results for mem_avg_temp_L0:\n",
            "  MSE: 0.045648376010351335\n",
            "  MAE: 0.11405595000185188\n",
            "  R²: 0.06194494447398624\n",
            "----------------------------------------\n",
            "Results for mem_avg_temp_L1:\n",
            "  MSE: 0.19544029868704152\n",
            "  MAE: 0.2860172587558821\n",
            "  R²: 0.034701108290374205\n",
            "----------------------------------------\n",
            "Results for total_area:\n",
            "  MSE: 5389011123615838.0\n",
            "  MAE: 53197563.67714667\n",
            "  R²: 0.9007898971741588\n",
            "----------------------------------------\n",
            "Results for avg_power:\n",
            "  MSE: 2.3154888402409673e-15\n",
            "  MAE: 3.596066979901768e-08\n",
            "  R²: 0.8763530160446213\n",
            "----------------------------------------\n",
            "Results for avg_cores_power:\n",
            "  MSE: 1.2783865081178016e-15\n",
            "  MAE: 2.7217925592783298e-08\n",
            "  R²: 0.8917443315686681\n",
            "----------------------------------------\n",
            "Results for avg_routers_power:\n",
            "  MSE: 2.1514426668165912e-16\n",
            "  MAE: 1.0015053423820425e-08\n",
            "  R²: 0.7756353184742233\n",
            "----------------------------------------\n",
            "Results for avg_power_per_router:\n",
            "  MSE: 3.4694390562552854e-21\n",
            "  MAE: 4.387024445693365e-11\n",
            "  R²: 0.8105089484565831\n",
            "----------------------------------------\n",
            "Results for layer_area:\n",
            "  MSE: 1347254356053924.8\n",
            "  MAE: 26598811.252804797\n",
            "  R²: 0.900789817254286\n",
            "----------------------------------------\n",
            "Results for area_per_core:\n",
            "  MSE: 0.0\n",
            "  MAE: 0.0\n",
            "  R²: 1.0\n",
            "----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "# Load your dataset\n",
        "df = pd.read_csv('pat_dataset.csv')\n",
        "\n",
        "# Columns containing the target variables\n",
        "target_columns = ['steady_state_temp_L0', 'steady_state_temp_L1', 'router_avg_temp_L0', 'router_avg_temp_L1',\n",
        "                  'core_avg_temp_L0', 'core_avg_temp_L1', 'mem_avg_temp_L0', 'mem_avg_temp_L1',\n",
        "                  'total_area', 'avg_power', 'avg_cores_power', 'avg_routers_power', 'avg_power_per_router',\n",
        "                  'layer_area', 'area_per_core']\n",
        "\n",
        "# Split the dataset into features (X) and target variables (y)\n",
        "X = df.drop(columns=target_columns)  # Features\n",
        "y = df[target_columns]  # Targets\n",
        "\n",
        "# Identify categorical columns\n",
        "categorical_columns = ['routing_type', 'selection_strategy', 'traffic_type']\n",
        "\n",
        "# One-hot encode categorical columns\n",
        "X = pd.get_dummies(X, columns=categorical_columns, drop_first=True)\n",
        "\n",
        "# Split the data into training and test sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize StandardScaler\n",
        "scaler_X = StandardScaler()\n",
        "scaler_y = {}\n",
        "\n",
        "# Scale the feature data\n",
        "X_train_scaled = scaler_X.fit_transform(X_train)\n",
        "X_test_scaled = scaler_X.transform(X_test)\n",
        "\n",
        "# Scale the target variables (y)\n",
        "for target in target_columns:\n",
        "    scaler_y[target] = StandardScaler()\n",
        "    y_train[target] = scaler_y[target].fit_transform(y_train[[target]])\n",
        "    y_test[target] = scaler_y[target].transform(y_test[[target]])\n",
        "\n",
        "# Function to evaluate models\n",
        "def evaluate_model(model, X_train, X_test, y_train, y_test, target):\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Calculate evaluation metrics\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    # Print the results\n",
        "    print(f\"Results for {target}:\")\n",
        "    print(f\"MSE: {mse}\")\n",
        "    print(f\"MAE: {mae}\")\n",
        "    print(f\"R²: {r2}\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "# Train and evaluate models for each target variable\n",
        "models = {\n",
        "    'Linear Regression': LinearRegression(),\n",
        "    'Decision Tree': DecisionTreeRegressor(),\n",
        "    'Random Forest': RandomForestRegressor(),\n",
        "    'Support Vector Regressor': SVR()\n",
        "}\n",
        "\n",
        "# Evaluate each model for each target variable\n",
        "for target in target_columns:\n",
        "    print(f\"\\nEvaluating models for {target}...\")\n",
        "\n",
        "    for model_name, model in models.items():\n",
        "        print(f\"\\nModel: {model_name}\")\n",
        "        evaluate_model(model, X_train_scaled, X_test_scaled, y_train[target], y_test[target], target)\n",
        "\n",
        "# Optionally, you can also apply other models and optimizations\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXi0oUT85sXM",
        "outputId": "4af5c691-50a6-4892-f6fa-de0b19ef721e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating models for steady_state_temp_L0...\n",
            "\n",
            "Model: Linear Regression\n",
            "Results for steady_state_temp_L0:\n",
            "MSE: 0.49606552122682745\n",
            "MAE: 0.5315647874219586\n",
            "R²: 0.5100783891806185\n",
            "----------------------------------------\n",
            "\n",
            "Model: Decision Tree\n",
            "Results for steady_state_temp_L0:\n",
            "MSE: 0.005983285730782671\n",
            "MAE: 0.020125885275033985\n",
            "R²: 0.9940908189386594\n",
            "----------------------------------------\n",
            "\n",
            "Model: Random Forest\n",
            "Results for steady_state_temp_L0:\n",
            "MSE: 0.003232749677317736\n",
            "MAE: 0.019136184493298625\n",
            "R²: 0.9968072888327928\n",
            "----------------------------------------\n",
            "\n",
            "Model: Support Vector Regressor\n",
            "Results for steady_state_temp_L0:\n",
            "MSE: 0.07287939272515927\n",
            "MAE: 0.13586405493715317\n",
            "R²: 0.9280232389641891\n",
            "----------------------------------------\n",
            "\n",
            "Evaluating models for steady_state_temp_L1...\n",
            "\n",
            "Model: Linear Regression\n",
            "Results for steady_state_temp_L1:\n",
            "MSE: 0.49927961589653364\n",
            "MAE: 0.5330637775287035\n",
            "R²: 0.5062256306810851\n",
            "----------------------------------------\n",
            "\n",
            "Model: Decision Tree\n",
            "Results for steady_state_temp_L1:\n",
            "MSE: 0.005964730643557326\n",
            "MAE: 0.020084372661659175\n",
            "R²: 0.9941010387408044\n",
            "----------------------------------------\n",
            "\n",
            "Model: Random Forest\n",
            "Results for steady_state_temp_L1:\n",
            "MSE: 0.0031705845807911415\n",
            "MAE: 0.019374610952222458\n",
            "R²: 0.9968643754883899\n",
            "----------------------------------------\n",
            "\n",
            "Model: Support Vector Regressor\n",
            "Results for steady_state_temp_L1:\n",
            "MSE: 0.07497886640141399\n",
            "MAE: 0.13629234339311364\n",
            "R²: 0.9258478790424369\n",
            "----------------------------------------\n",
            "\n",
            "Evaluating models for router_avg_temp_L0...\n",
            "\n",
            "Model: Linear Regression\n",
            "Results for router_avg_temp_L0:\n",
            "MSE: 0.6507125263451268\n",
            "MAE: 0.473154461225902\n",
            "R²: 0.3250407966488047\n",
            "----------------------------------------\n",
            "\n",
            "Model: Decision Tree\n",
            "Results for router_avg_temp_L0:\n",
            "MSE: 0.005506880836427066\n",
            "MAE: 0.03623122808418251\n",
            "R²: 0.9942879232351931\n",
            "----------------------------------------\n",
            "\n",
            "Model: Random Forest\n",
            "Results for router_avg_temp_L0:\n",
            "MSE: 0.0035395217320548862\n",
            "MAE: 0.030428241907590536\n",
            "R²: 0.9963285895510102\n",
            "----------------------------------------\n",
            "\n",
            "Model: Support Vector Regressor\n",
            "Results for router_avg_temp_L0:\n",
            "MSE: 0.5011052971497383\n",
            "MAE: 0.2322700433538349\n",
            "R²: 0.48022265060890756\n",
            "----------------------------------------\n",
            "\n",
            "Evaluating models for router_avg_temp_L1...\n",
            "\n",
            "Model: Linear Regression\n",
            "Results for router_avg_temp_L1:\n",
            "MSE: 0.875424572567155\n",
            "MAE: 0.604580581153446\n",
            "R²: 0.1345225660455277\n",
            "----------------------------------------\n",
            "\n",
            "Model: Decision Tree\n",
            "Results for router_avg_temp_L1:\n",
            "MSE: 0.0018463151298058744\n",
            "MAE: 0.020246961038655975\n",
            "R²: 0.9981746638935096\n",
            "----------------------------------------\n",
            "\n",
            "Model: Random Forest\n",
            "Results for router_avg_temp_L1:\n",
            "MSE: 0.0013111752325698802\n",
            "MAE: 0.01745049696633663\n",
            "R²: 0.9987037231860861\n",
            "----------------------------------------\n",
            "\n",
            "Model: Support Vector Regressor\n",
            "Results for router_avg_temp_L1:\n",
            "MSE: 0.26016657561185397\n",
            "MAE: 0.23506374954442155\n",
            "R²: 0.7427896048188702\n",
            "----------------------------------------\n",
            "\n",
            "Evaluating models for core_avg_temp_L0...\n",
            "\n",
            "Model: Linear Regression\n",
            "Results for core_avg_temp_L0:\n",
            "MSE: 0.6285077147911242\n",
            "MAE: 0.520746264956555\n",
            "R²: 0.3337650427236797\n",
            "----------------------------------------\n",
            "\n",
            "Model: Decision Tree\n",
            "Results for core_avg_temp_L0:\n",
            "MSE: 0.0102266556370176\n",
            "MAE: 0.05084323152608355\n",
            "R²: 0.9891594719984107\n",
            "----------------------------------------\n",
            "\n",
            "Model: Random Forest\n",
            "Results for core_avg_temp_L0:\n",
            "MSE: 0.0067890986055210234\n",
            "MAE: 0.04325051175650307\n",
            "R²: 0.9928033742260471\n",
            "----------------------------------------\n",
            "\n",
            "Model: Support Vector Regressor\n",
            "Results for core_avg_temp_L0:\n",
            "MSE: 0.3945775448062948\n",
            "MAE: 0.26378517026367865\n",
            "R²: 0.5817372682631554\n",
            "----------------------------------------\n",
            "\n",
            "Evaluating models for core_avg_temp_L1...\n",
            "\n",
            "Model: Linear Regression\n",
            "Results for core_avg_temp_L1:\n",
            "MSE: 0.9019849608422335\n",
            "MAE: 0.6430488474878876\n",
            "R²: 0.08832369386021754\n",
            "----------------------------------------\n",
            "\n",
            "Model: Decision Tree\n",
            "Results for core_avg_temp_L1:\n",
            "MSE: 0.003503989299386115\n",
            "MAE: 0.029650181657154325\n",
            "R²: 0.9964583622123424\n",
            "----------------------------------------\n",
            "\n",
            "Model: Random Forest\n",
            "Results for core_avg_temp_L1:\n",
            "MSE: 0.002445168087627036\n",
            "MAE: 0.026367749399782158\n",
            "R²: 0.997528559890913\n",
            "----------------------------------------\n",
            "\n",
            "Model: Support Vector Regressor\n",
            "Results for core_avg_temp_L1:\n",
            "MSE: 0.25493625108671814\n",
            "MAE: 0.2558303457422363\n",
            "R²: 0.7423245954402161\n",
            "----------------------------------------\n",
            "\n",
            "Evaluating models for mem_avg_temp_L0...\n",
            "\n",
            "Model: Linear Regression\n",
            "Results for mem_avg_temp_L0:\n",
            "MSE: 0.8715019068089909\n",
            "MAE: 0.4983557244444326\n",
            "R²: 0.06194494447398646\n",
            "----------------------------------------\n",
            "\n",
            "Model: Decision Tree\n",
            "Results for mem_avg_temp_L0:\n",
            "MSE: 0.007419772962640271\n",
            "MAE: 0.049272693858645904\n",
            "R²: 0.9920136083649609\n",
            "----------------------------------------\n",
            "\n",
            "Model: Random Forest\n",
            "Results for mem_avg_temp_L0:\n",
            "MSE: 0.0047827951575963226\n",
            "MAE: 0.04083295517668964\n",
            "R²: 0.9948519617202491\n",
            "----------------------------------------\n",
            "\n",
            "Model: Support Vector Regressor\n",
            "Results for mem_avg_temp_L0:\n",
            "MSE: 0.7754521684867711\n",
            "MAE: 0.32838716678868496\n",
            "R²: 0.16532962087132252\n",
            "----------------------------------------\n",
            "\n",
            "Evaluating models for mem_avg_temp_L1...\n",
            "\n",
            "Model: Linear Regression\n",
            "Results for mem_avg_temp_L1:\n",
            "MSE: 0.9615234323754502\n",
            "MAE: 0.6344028383457166\n",
            "R²: 0.034701108290374094\n",
            "----------------------------------------\n",
            "\n",
            "Model: Decision Tree\n",
            "Results for mem_avg_temp_L1:\n",
            "MSE: 0.002095251961354358\n",
            "MAE: 0.023292990308535468\n",
            "R²: 0.9978965209499356\n",
            "----------------------------------------\n",
            "\n",
            "Model: Random Forest\n",
            "Results for mem_avg_temp_L1:\n",
            "MSE: 0.0014211277262045476\n",
            "MAE: 0.019878263404219294\n",
            "R²: 0.9985732921602399\n",
            "----------------------------------------\n",
            "\n",
            "Model: Support Vector Regressor\n",
            "Results for mem_avg_temp_L1:\n",
            "MSE: 0.28436381641225417\n",
            "MAE: 0.2581246131586203\n",
            "R²: 0.7145196179494825\n",
            "----------------------------------------\n",
            "\n",
            "Evaluating models for total_area...\n",
            "\n",
            "Model: Linear Regression\n",
            "Results for total_area:\n",
            "MSE: 0.1004054496446253\n",
            "MAE: 0.22962324274094\n",
            "R²: 0.9007898971741588\n",
            "----------------------------------------\n",
            "\n",
            "Model: Decision Tree\n",
            "Results for total_area:\n",
            "MSE: 4.81367532877505e-32\n",
            "MAE: 1.2797958975500037e-16\n",
            "R²: 1.0\n",
            "----------------------------------------\n",
            "\n",
            "Model: Random Forest\n",
            "Results for total_area:\n",
            "MSE: 1.5472608417972797e-09\n",
            "MAE: 5.626965177048578e-06\n",
            "R²: 0.9999999984711596\n",
            "----------------------------------------\n",
            "\n",
            "Model: Support Vector Regressor\n",
            "Results for total_area:\n",
            "MSE: 0.003261441318946009\n",
            "MAE: 0.048698844888551786\n",
            "R²: 0.9967773867876861\n",
            "----------------------------------------\n",
            "\n",
            "Evaluating models for avg_power...\n",
            "\n",
            "Model: Linear Regression\n",
            "Results for avg_power:\n",
            "MSE: 0.12785572045258073\n",
            "MAE: 0.2672184915279285\n",
            "R²: 0.8763530160446213\n",
            "----------------------------------------\n",
            "\n",
            "Model: Decision Tree\n",
            "Results for avg_power:\n",
            "MSE: 0.001429761381064562\n",
            "MAE: 0.010716557682213058\n",
            "R²: 0.9986173033015752\n",
            "----------------------------------------\n",
            "\n",
            "Model: Random Forest\n",
            "Results for avg_power:\n",
            "MSE: 0.000891806857343597\n",
            "MAE: 0.010810006402985947\n",
            "R²: 0.9991375495144766\n",
            "----------------------------------------\n",
            "\n",
            "Model: Support Vector Regressor\n",
            "Results for avg_power:\n",
            "MSE: 0.0033219335996013863\n",
            "MAE: 0.044699491956115965\n",
            "R²: 0.9967874173401331\n",
            "----------------------------------------\n",
            "\n",
            "Evaluating models for avg_cores_power...\n",
            "\n",
            "Model: Linear Regression\n",
            "Results for avg_cores_power:\n",
            "MSE: 0.11113472151570268\n",
            "MAE: 0.25377498805883586\n",
            "R²: 0.8917443315686681\n",
            "----------------------------------------\n",
            "\n",
            "Model: Decision Tree\n",
            "Results for avg_cores_power:\n",
            "MSE: 0.0008206891436384049\n",
            "MAE: 0.007469181358509568\n",
            "R²: 0.99920057160708\n",
            "----------------------------------------\n",
            "\n",
            "Model: Random Forest\n",
            "Results for avg_cores_power:\n",
            "MSE: 0.0005398096395895731\n",
            "MAE: 0.008525776782117673\n",
            "R²: 0.9994741746543074\n",
            "----------------------------------------\n",
            "\n",
            "Model: Support Vector Regressor\n",
            "Results for avg_cores_power:\n",
            "MSE: 0.0026114111405001776\n",
            "MAE: 0.042108478684365284\n",
            "R²: 0.997456240005749\n",
            "----------------------------------------\n",
            "\n",
            "Evaluating models for avg_routers_power...\n",
            "\n",
            "Model: Linear Regression\n",
            "Results for avg_routers_power:\n",
            "MSE: 0.23881753563019747\n",
            "MAE: 0.33367332419079193\n",
            "R²: 0.7756353184742233\n",
            "----------------------------------------\n",
            "\n",
            "Model: Decision Tree\n",
            "Results for avg_routers_power:\n",
            "MSE: 0.0027347577843115124\n",
            "MAE: 0.01679565652327081\n",
            "R²: 0.997430745369229\n",
            "----------------------------------------\n",
            "\n",
            "Model: Random Forest\n",
            "Results for avg_routers_power:\n",
            "MSE: 0.0017338632539977501\n",
            "MAE: 0.0153718871770147\n",
            "R²: 0.9983710673683743\n",
            "----------------------------------------\n",
            "\n",
            "Model: Support Vector Regressor\n",
            "Results for avg_routers_power:\n",
            "MSE: 0.006475727609104034\n",
            "MAE: 0.05504845760702598\n",
            "R²: 0.9939161730363296\n",
            "----------------------------------------\n",
            "\n",
            "Evaluating models for avg_power_per_router...\n",
            "\n",
            "Model: Linear Regression\n",
            "Results for avg_power_per_router:\n",
            "MSE: 0.18879009890041715\n",
            "MAE: 0.32361603299749647\n",
            "R²: 0.8105089484565831\n",
            "----------------------------------------\n",
            "\n",
            "Model: Decision Tree\n",
            "Results for avg_power_per_router:\n",
            "MSE: 0.007624466652467639\n",
            "MAE: 0.025391576955790387\n",
            "R²: 0.9923472247122669\n",
            "----------------------------------------\n",
            "\n",
            "Model: Random Forest\n",
            "Results for avg_power_per_router:\n",
            "MSE: 0.004068991651110913\n",
            "MAE: 0.019955466770490617\n",
            "R²: 0.9959159007215888\n",
            "----------------------------------------\n",
            "\n",
            "Model: Support Vector Regressor\n",
            "Results for avg_power_per_router:\n",
            "MSE: 0.01582646646374961\n",
            "MAE: 0.08211689053174358\n",
            "R²: 0.9841147719615613\n",
            "----------------------------------------\n",
            "\n",
            "Evaluating models for layer_area...\n",
            "\n",
            "Model: Linear Regression\n",
            "Results for layer_area:\n",
            "MSE: 0.10040552934240712\n",
            "MAE: 0.22962345356954186\n",
            "R²: 0.9007898172542859\n",
            "----------------------------------------\n",
            "\n",
            "Model: Decision Tree\n",
            "Results for layer_area:\n",
            "MSE: 3.85366298564178e-32\n",
            "MAE: 1.2311317896414942e-16\n",
            "R²: 1.0\n",
            "----------------------------------------\n",
            "\n",
            "Model: Random Forest\n",
            "Results for layer_area:\n",
            "MSE: 2.1939307649181245e-09\n",
            "MAE: 6.184932724899009e-06\n",
            "R²: 0.9999999978321884\n",
            "----------------------------------------\n",
            "\n",
            "Model: Support Vector Regressor\n",
            "Results for layer_area:\n",
            "MSE: 0.003256434170061004\n",
            "MAE: 0.048656885971032175\n",
            "R²: 0.9967823342874934\n",
            "----------------------------------------\n",
            "\n",
            "Evaluating models for area_per_core...\n",
            "\n",
            "Model: Linear Regression\n",
            "Results for area_per_core:\n",
            "MSE: 0.0\n",
            "MAE: 0.0\n",
            "R²: 1.0\n",
            "----------------------------------------\n",
            "\n",
            "Model: Decision Tree\n",
            "Results for area_per_core:\n",
            "MSE: 0.0\n",
            "MAE: 0.0\n",
            "R²: 1.0\n",
            "----------------------------------------\n",
            "\n",
            "Model: Random Forest\n",
            "Results for area_per_core:\n",
            "MSE: 0.0\n",
            "MAE: 0.0\n",
            "R²: 1.0\n",
            "----------------------------------------\n",
            "\n",
            "Model: Support Vector Regressor\n",
            "Results for area_per_core:\n",
            "MSE: 0.0\n",
            "MAE: 0.0\n",
            "R²: 1.0\n",
            "----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "# Load your dataset\n",
        "df = pd.read_csv('pat_dataset.csv')\n",
        "\n",
        "# Columns containing the target variables\n",
        "target_columns = ['steady_state_temp_L0', 'steady_state_temp_L1', 'router_avg_temp_L0', 'router_avg_temp_L1',\n",
        "                  'core_avg_temp_L0', 'core_avg_temp_L1', 'mem_avg_temp_L0', 'mem_avg_temp_L1',\n",
        "                  'total_area', 'avg_power', 'avg_cores_power', 'avg_routers_power', 'avg_power_per_router',\n",
        "                  'layer_area', 'area_per_core']\n",
        "\n",
        "# Split the dataset into features (X) and target variables (y)\n",
        "X = df.drop(columns=target_columns)  # Features\n",
        "y = df[target_columns]  # Targets\n",
        "\n",
        "# Identify categorical columns\n",
        "categorical_columns = ['routing_type', 'selection_strategy', 'traffic_type']\n",
        "\n",
        "# One-hot encode categorical columns\n",
        "X = pd.get_dummies(X, columns=categorical_columns, drop_first=True)\n",
        "\n",
        "# Split the data into training and test sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize StandardScaler\n",
        "scaler_X = StandardScaler()\n",
        "scaler_y = {}\n",
        "\n",
        "# Scale the feature data\n",
        "X_train_scaled = scaler_X.fit_transform(X_train)\n",
        "X_test_scaled = scaler_X.transform(X_test)\n",
        "\n",
        "# Scale the target variables (y)\n",
        "for target in target_columns:\n",
        "    scaler_y[target] = StandardScaler()\n",
        "    y_train[target] = scaler_y[target].fit_transform(y_train[[target]])\n",
        "    y_test[target] = scaler_y[target].transform(y_test[[target]])\n",
        "\n",
        "from sklearn.ensemble import GradientBoostingRegressor, AdaBoostRegressor\n",
        "from sklearn.linear_model import ElasticNet\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "# Initialize the additional models\n",
        "models=({\n",
        "    'Gradient Boosting': GradientBoostingRegressor(),\n",
        "    'AdaBoost': AdaBoostRegressor(),\n",
        "    'ElasticNet': ElasticNet()\n",
        "})\n",
        "\n",
        "# Function to evaluate models (same as before)\n",
        "def evaluate_model(model, X_train, X_test, y_train, y_test, target):\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Calculate evaluation metrics\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    # Print the results\n",
        "    print(f\"Results for {target}:\")\n",
        "    print(f\"MSE: {mse}\")\n",
        "    print(f\"MAE: {mae}\")\n",
        "    print(f\"R²: {r2}\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "# Evaluate each model for each target variable\n",
        "for target in target_columns:\n",
        "    print(f\"\\nEvaluating models for {target}...\")\n",
        "\n",
        "    for model_name, model in models.items():\n",
        "        print(f\"\\nModel: {model_name}\")\n",
        "        evaluate_model(model, X_train_scaled, X_test_scaled, y_train[target], y_test[target], target)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aXFL5W6K7IqO",
        "outputId": "129a6717-0b9e-4b9e-8b30-8ba6656ce2e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating models for steady_state_temp_L0...\n",
            "\n",
            "Model: Gradient Boosting\n",
            "Results for steady_state_temp_L0:\n",
            "MSE: 0.0672082395482736\n",
            "MAE: 0.18281762749140512\n",
            "R²: 0.933624153320728\n",
            "----------------------------------------\n",
            "\n",
            "Model: AdaBoost\n",
            "Results for steady_state_temp_L0:\n",
            "MSE: 0.27145204679340235\n",
            "MAE: 0.4464060113977227\n",
            "R²: 0.7319099628284151\n",
            "----------------------------------------\n",
            "\n",
            "Model: ElasticNet\n",
            "Results for steady_state_temp_L0:\n",
            "MSE: 0.9596050294203804\n",
            "MAE: 0.780451375998598\n",
            "R²: 0.052279947613928734\n",
            "----------------------------------------\n",
            "\n",
            "Evaluating models for steady_state_temp_L1...\n",
            "\n",
            "Model: Gradient Boosting\n",
            "Results for steady_state_temp_L1:\n",
            "MSE: 0.06420044183395518\n",
            "MAE: 0.17706143601911867\n",
            "R²: 0.9365074566089912\n",
            "----------------------------------------\n",
            "\n",
            "Model: AdaBoost\n",
            "Results for steady_state_temp_L1:\n",
            "MSE: 0.24618600395856477\n",
            "MAE: 0.4215740851082759\n",
            "R²: 0.7565285363763472\n",
            "----------------------------------------\n",
            "\n",
            "Model: ElasticNet\n",
            "Results for steady_state_temp_L1:\n",
            "MSE: 0.9548282351212037\n",
            "MAE: 0.779790852652434\n",
            "R²: 0.05570006346390033\n",
            "----------------------------------------\n",
            "\n",
            "Evaluating models for router_avg_temp_L0...\n",
            "\n",
            "Model: Gradient Boosting\n",
            "Results for router_avg_temp_L0:\n",
            "MSE: 0.06791092982514488\n",
            "MAE: 0.16327327904980748\n",
            "R²: 0.9295585911783916\n",
            "----------------------------------------\n",
            "\n",
            "Model: AdaBoost\n",
            "Results for router_avg_temp_L0:\n",
            "MSE: 0.2114989583672541\n",
            "MAE: 0.3603307986444902\n",
            "R²: 0.7806202237246381\n",
            "----------------------------------------\n",
            "\n",
            "Model: ElasticNet\n",
            "Results for router_avg_temp_L0:\n",
            "MSE: 0.959793767311335\n",
            "MAE: 0.7446236776292952\n",
            "R²: 0.0044426527263320414\n",
            "----------------------------------------\n",
            "\n",
            "Evaluating models for router_avg_temp_L1...\n",
            "\n",
            "Model: Gradient Boosting\n",
            "Results for router_avg_temp_L1:\n",
            "MSE: 0.06155186618802941\n",
            "MAE: 0.1309705375673053\n",
            "R²: 0.9391475258144663\n",
            "----------------------------------------\n",
            "\n",
            "Model: AdaBoost\n",
            "Results for router_avg_temp_L1:\n",
            "MSE: 0.1816343797514963\n",
            "MAE: 0.29258104226186255\n",
            "R²: 0.8204294672192582\n",
            "----------------------------------------\n",
            "\n",
            "Model: ElasticNet\n",
            "Results for router_avg_temp_L1:\n",
            "MSE: 1.0115825624902461\n",
            "MAE: 0.6124041478887731\n",
            "R²: -8.830897876910271e-05\n",
            "----------------------------------------\n",
            "\n",
            "Evaluating models for core_avg_temp_L0...\n",
            "\n",
            "Model: Gradient Boosting\n",
            "Results for core_avg_temp_L0:\n",
            "MSE: 0.0889844136350447\n",
            "MAE: 0.19406950385046917\n",
            "R²: 0.9056741458836273\n",
            "----------------------------------------\n",
            "\n",
            "Model: AdaBoost\n",
            "Results for core_avg_temp_L0:\n",
            "MSE: 0.3957046552742647\n",
            "MAE: 0.4822146418937974\n",
            "R²: 0.5805425010760523\n",
            "----------------------------------------\n",
            "\n",
            "Model: ElasticNet\n",
            "Results for core_avg_temp_L0:\n",
            "MSE: 0.94365179109986\n",
            "MAE: 0.7474813477260261\n",
            "R²: -0.0002960917290824039\n",
            "----------------------------------------\n",
            "\n",
            "Evaluating models for core_avg_temp_L1...\n",
            "\n",
            "Model: Gradient Boosting\n",
            "Results for core_avg_temp_L1:\n",
            "MSE: 0.07235717266955062\n",
            "MAE: 0.16093421975014008\n",
            "R²: 0.926865388264902\n",
            "----------------------------------------\n",
            "\n",
            "Model: AdaBoost\n",
            "Results for core_avg_temp_L1:\n",
            "MSE: 0.2641494735052191\n",
            "MAE: 0.40502793178595087\n",
            "R²: 0.7330123818814667\n",
            "----------------------------------------\n",
            "\n",
            "Model: ElasticNet\n",
            "Results for core_avg_temp_L1:\n",
            "MSE: 0.9893710370745131\n",
            "MAE: 0.6747368750302888\n",
            "R²: -1.2989568509702565e-06\n",
            "----------------------------------------\n",
            "\n",
            "Evaluating models for mem_avg_temp_L0...\n",
            "\n",
            "Model: Gradient Boosting\n",
            "Results for mem_avg_temp_L0:\n",
            "MSE: 0.0612976794897561\n",
            "MAE: 0.15235403640589537\n",
            "R²: 0.9340212595197667\n",
            "----------------------------------------\n",
            "\n",
            "Model: AdaBoost\n",
            "Results for mem_avg_temp_L0:\n",
            "MSE: 0.19750310247058744\n",
            "MAE: 0.33881117920971554\n",
            "R²: 0.7874143678778976\n",
            "----------------------------------------\n",
            "\n",
            "Model: ElasticNet\n",
            "Results for mem_avg_temp_L0:\n",
            "MSE: 0.9293170819616646\n",
            "MAE: 0.6018511599666814\n",
            "R²: -0.00028534660668944056\n",
            "----------------------------------------\n",
            "\n",
            "Evaluating models for mem_avg_temp_L1...\n",
            "\n",
            "Model: Gradient Boosting\n",
            "Results for mem_avg_temp_L1:\n",
            "MSE: 0.0440741221819864\n",
            "MAE: 0.10507871115739481\n",
            "R²: 0.955752819054821\n",
            "----------------------------------------\n",
            "\n",
            "Model: AdaBoost\n",
            "Results for mem_avg_temp_L1:\n",
            "MSE: 0.13777681527740093\n",
            "MAE: 0.27815111766623934\n",
            "R²: 0.8616821986730059\n",
            "----------------------------------------\n",
            "\n",
            "Model: ElasticNet\n",
            "Results for mem_avg_temp_L1:\n",
            "MSE: 0.996089899791813\n",
            "MAE: 0.5601942209238238\n",
            "R²: -1.0857111787387907e-06\n",
            "----------------------------------------\n",
            "\n",
            "Evaluating models for total_area...\n",
            "\n",
            "Model: Gradient Boosting\n",
            "Results for total_area:\n",
            "MSE: 0.0005052727000390047\n",
            "MAE: 0.016251655546511066\n",
            "R²: 0.9995007426718033\n",
            "----------------------------------------\n",
            "\n",
            "Model: AdaBoost\n",
            "Results for total_area:\n",
            "MSE: 0.033438528394363475\n",
            "MAE: 0.14468686764655186\n",
            "R²: 0.9669595639271439\n",
            "----------------------------------------\n",
            "\n",
            "Model: ElasticNet\n",
            "Results for total_area:\n",
            "MSE: 0.7284210593462804\n",
            "MAE: 0.6757324280164758\n",
            "R²: 0.280250938031419\n",
            "----------------------------------------\n",
            "\n",
            "Evaluating models for avg_power...\n",
            "\n",
            "Model: Gradient Boosting\n",
            "Results for avg_power:\n",
            "MSE: 0.009793961119024601\n",
            "MAE: 0.06625658688481915\n",
            "R²: 0.9905284351059382\n",
            "----------------------------------------\n",
            "\n",
            "Model: AdaBoost\n",
            "Results for avg_power:\n",
            "MSE: 0.11599109893173982\n",
            "MAE: 0.29694077469033475\n",
            "R²: 0.8878270796346673\n",
            "----------------------------------------\n",
            "\n",
            "Model: ElasticNet\n",
            "Results for avg_power:\n",
            "MSE: 0.8146894468236915\n",
            "MAE: 0.7299400056945187\n",
            "R²: 0.21212838499951514\n",
            "----------------------------------------\n",
            "\n",
            "Evaluating models for avg_cores_power...\n",
            "\n",
            "Model: Gradient Boosting\n",
            "Results for avg_cores_power:\n",
            "MSE: 0.005157359556573741\n",
            "MAE: 0.05077473188436855\n",
            "R²: 0.9949762468603592\n",
            "----------------------------------------\n",
            "\n",
            "Model: AdaBoost\n",
            "Results for avg_cores_power:\n",
            "MSE: 0.07812963632836738\n",
            "MAE: 0.2419256482040767\n",
            "R²: 0.9238943879134189\n",
            "----------------------------------------\n",
            "\n",
            "Model: ElasticNet\n",
            "Results for avg_cores_power:\n",
            "MSE: 0.7727198776880141\n",
            "MAE: 0.7119777068920736\n",
            "R²: 0.24729818252638913\n",
            "----------------------------------------\n",
            "\n",
            "Evaluating models for avg_routers_power...\n",
            "\n",
            "Model: Gradient Boosting\n",
            "Results for avg_routers_power:\n",
            "MSE: 0.03330242977149199\n",
            "MAE: 0.11249118742590442\n",
            "R²: 0.9687129798488275\n",
            "----------------------------------------\n",
            "\n",
            "Model: AdaBoost\n",
            "Results for avg_routers_power:\n",
            "MSE: 0.22443582712021856\n",
            "MAE: 0.41830337437025233\n",
            "R²: 0.7891466690587737\n",
            "----------------------------------------\n",
            "\n",
            "Model: ElasticNet\n",
            "Results for avg_routers_power:\n",
            "MSE: 1.006258563311037\n",
            "MAE: 0.7562383004486506\n",
            "R²: 0.05463859052852993\n",
            "----------------------------------------\n",
            "\n",
            "Evaluating models for avg_power_per_router...\n",
            "\n",
            "Model: Gradient Boosting\n",
            "Results for avg_power_per_router:\n",
            "MSE: 0.04179387101672933\n",
            "MAE: 0.13431065662917646\n",
            "R²: 0.9580509538733417\n",
            "----------------------------------------\n",
            "\n",
            "Model: AdaBoost\n",
            "Results for avg_power_per_router:\n",
            "MSE: 0.12699208668647508\n",
            "MAE: 0.29766878497548416\n",
            "R²: 0.8725364085083397\n",
            "----------------------------------------\n",
            "\n",
            "Model: ElasticNet\n",
            "Results for avg_power_per_router:\n",
            "MSE: 0.7382510502198899\n",
            "MAE: 0.7249382762145791\n",
            "R²: 0.25900792136885875\n",
            "----------------------------------------\n",
            "\n",
            "Evaluating models for layer_area...\n",
            "\n",
            "Model: Gradient Boosting\n",
            "Results for layer_area:\n",
            "MSE: 0.0005052713981616429\n",
            "MAE: 0.016251740826679312\n",
            "R²: 0.9995007439522893\n",
            "----------------------------------------\n",
            "\n",
            "Model: AdaBoost\n",
            "Results for layer_area:\n",
            "MSE: 0.03367754715661718\n",
            "MAE: 0.14612175161775529\n",
            "R²: 0.9667233903379838\n",
            "----------------------------------------\n",
            "\n",
            "Model: ElasticNet\n",
            "Results for layer_area:\n",
            "MSE: 0.7284211244241907\n",
            "MAE: 0.6757323853563468\n",
            "R²: 0.2802508652335741\n",
            "----------------------------------------\n",
            "\n",
            "Evaluating models for area_per_core...\n",
            "\n",
            "Model: Gradient Boosting\n",
            "Results for area_per_core:\n",
            "MSE: 0.0\n",
            "MAE: 0.0\n",
            "R²: 1.0\n",
            "----------------------------------------\n",
            "\n",
            "Model: AdaBoost\n",
            "Results for area_per_core:\n",
            "MSE: 0.0\n",
            "MAE: 0.0\n",
            "R²: 1.0\n",
            "----------------------------------------\n",
            "\n",
            "Model: ElasticNet\n",
            "Results for area_per_core:\n",
            "MSE: 0.0\n",
            "MAE: 0.0\n",
            "R²: 1.0\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
            "  model = cd_fast.enet_coordinate_descent(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HxCZUM3x-kbV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XGOi8z2W-lsL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Load your dataset\n",
        "df = pd.read_csv('pat_dataset.csv')\n",
        "\n",
        "# Columns containing the target variables\n",
        "target_columns = ['steady_state_temp_L0', 'steady_state_temp_L1', 'router_avg_temp_L0', 'router_avg_temp_L1',\n",
        "                  'core_avg_temp_L0', 'core_avg_temp_L1', 'mem_avg_temp_L0', 'mem_avg_temp_L1',\n",
        "                  'total_area', 'avg_power', 'avg_cores_power', 'avg_routers_power', 'avg_power_per_router',\n",
        "                  'layer_area', 'area_per_core']\n",
        "\n",
        "# Split the dataset into features (X) and target variables (y)\n",
        "X = df.drop(columns=target_columns)  # Features\n",
        "y = df[target_columns]  # Targets\n",
        "\n",
        "# Identify categorical columns\n",
        "categorical_columns = ['routing_type', 'selection_strategy', 'traffic_type']\n",
        "\n",
        "# One-hot encode categorical columns\n",
        "X = pd.get_dummies(X, columns=categorical_columns, drop_first=True)\n",
        "\n",
        "# Split the data into training and test sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize StandardScaler\n",
        "scaler_X = StandardScaler()\n",
        "scaler_y = {}\n",
        "\n",
        "# Scale the feature data\n",
        "X_train_scaled = scaler_X.fit_transform(X_train)\n",
        "X_test_scaled = scaler_X.transform(X_test)\n",
        "\n",
        "# Scale the target variables (y)\n",
        "for target in target_columns:\n",
        "    scaler_y[target] = StandardScaler()\n",
        "    y_train[target] = scaler_y[target].fit_transform(y_train[[target]])\n",
        "    y_test[target] = scaler_y[target].transform(y_test[[target]])\n",
        "\n",
        "# Reshape the feature data for CNN (samples, timesteps, features)\n",
        "X_train_scaled_reshaped = X_train_scaled.reshape(X_train_scaled.shape[0], X_train_scaled.shape[1], 1)\n",
        "X_test_scaled_reshaped = X_test_scaled.reshape(X_test_scaled.shape[0], X_test_scaled.shape[1], 1)\n",
        "\n",
        "# Build CNN model for regression\n",
        "cnn_model = Sequential()\n",
        "\n",
        "# 1D Convolutional Layer\n",
        "cnn_model.add(Conv1D(64, kernel_size=3, activation='relu', input_shape=(X_train_scaled_reshaped.shape[1], 1)))\n",
        "\n",
        "# Max Pooling Layer with pool_size=1 to prevent reducing dimensions to 0\n",
        "cnn_model.add(MaxPooling1D(pool_size=1))\n",
        "\n",
        "# 2nd Convolutional Layer\n",
        "cnn_model.add(Conv1D(128, kernel_size=3, activation='relu'))\n",
        "\n",
        "# Max Pooling Layer with pool_size=1 to maintain the dimension\n",
        "cnn_model.add(MaxPooling1D(pool_size=1))\n",
        "\n",
        "# Flatten the output from the convolutional layers\n",
        "cnn_model.add(Flatten())\n",
        "\n",
        "# Fully Connected Layer\n",
        "cnn_model.add(Dense(64, activation='relu'))\n",
        "\n",
        "# Output layer for regression (one neuron per target)\n",
        "cnn_model.add(Dense(len(target_columns)))\n",
        "\n",
        "# Compile the CNN model\n",
        "cnn_model.compile(optimizer=Adam(), loss='mean_squared_error')\n",
        "\n",
        "# Train the CNN model\n",
        "cnn_history = cnn_model.fit(X_train_scaled_reshaped, y_train, epochs=50, batch_size=32, validation_data=(X_test_scaled_reshaped, y_test))\n",
        "\n",
        "# Predict with the CNN model\n",
        "y_pred_cnn = cnn_model.predict(X_test_scaled_reshaped)\n",
        "\n",
        "# Inverse transform the predictions and actual values to original scale\n",
        "y_pred_cnn = pd.DataFrame(y_pred_cnn, columns=target_columns)\n",
        "y_test_inv = y_test.copy()\n",
        "\n",
        "for target in target_columns:\n",
        "    y_pred_cnn[target] = scaler_y[target].inverse_transform(y_pred_cnn[[target]])\n",
        "    y_test_inv[target] = scaler_y[target].inverse_transform(y_test_inv[[target]])\n",
        "\n",
        "# Calculate and print evaluation metrics for CNN\n",
        "for target in target_columns:\n",
        "    mse = mean_squared_error(y_test_inv[target], y_pred_cnn[target])\n",
        "    mae = mean_absolute_error(y_test_inv[target], y_pred_cnn[target])\n",
        "    r2 = r2_score(y_test_inv[target], y_pred_cnn[target])\n",
        "\n",
        "    print(f\"Results for CNN Regression ({target}):\")\n",
        "    print(f\"MSE: {mse}\")\n",
        "    print(f\"MAE: {mae}\")\n",
        "    print(f\"R²: {r2}\")\n",
        "    print(\"-\" * 40)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvCvnu_X8QHp",
        "outputId": "35b32aaf-af91-4392-b596-afe7bc882cc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.4262 - val_loss: 0.1117\n",
            "Epoch 2/50\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0971 - val_loss: 0.0823\n",
            "Epoch 3/50\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0726 - val_loss: 0.0517\n",
            "Epoch 4/50\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0491 - val_loss: 0.0464\n",
            "Epoch 5/50\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0418 - val_loss: 0.0349\n",
            "Epoch 6/50\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0369 - val_loss: 0.0319\n",
            "Epoch 7/50\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0311 - val_loss: 0.0250\n",
            "Epoch 8/50\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0238 - val_loss: 0.0261\n",
            "Epoch 9/50\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0207 - val_loss: 0.0224\n",
            "Epoch 10/50\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0185 - val_loss: 0.0227\n",
            "Epoch 11/50\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0188 - val_loss: 0.0187\n",
            "Epoch 12/50\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0167 - val_loss: 0.0161\n",
            "Epoch 13/50\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0139 - val_loss: 0.0162\n",
            "Epoch 14/50\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0129 - val_loss: 0.0126\n",
            "Epoch 15/50\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0114 - val_loss: 0.0141\n",
            "Epoch 16/50\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0109 - val_loss: 0.0115\n",
            "Epoch 17/50\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0120 - val_loss: 0.0122\n",
            "Epoch 18/50\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0100 - val_loss: 0.0132\n",
            "Epoch 19/50\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0099 - val_loss: 0.0148\n",
            "Epoch 20/50\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0106 - val_loss: 0.0092\n",
            "Epoch 21/50\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0090 - val_loss: 0.0095\n",
            "Epoch 22/50\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0088 - val_loss: 0.0121\n",
            "Epoch 23/50\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0107 - val_loss: 0.0129\n",
            "Epoch 24/50\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0079 - val_loss: 0.0102\n",
            "Epoch 25/50\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0088 - val_loss: 0.0110\n",
            "Epoch 26/50\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0084 - val_loss: 0.0078\n",
            "Epoch 27/50\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0074 - val_loss: 0.0103\n",
            "Epoch 28/50\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0079 - val_loss: 0.0093\n",
            "Epoch 29/50\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0088 - val_loss: 0.0081\n",
            "Epoch 30/50\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0078 - val_loss: 0.0098\n",
            "Epoch 31/50\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0081 - val_loss: 0.0085\n",
            "Epoch 32/50\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0068 - val_loss: 0.0075\n",
            "Epoch 33/50\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0075 - val_loss: 0.0073\n",
            "Epoch 34/50\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0068 - val_loss: 0.0087\n",
            "Epoch 35/50\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0067 - val_loss: 0.0074\n",
            "Epoch 36/50\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0065 - val_loss: 0.0072\n",
            "Epoch 37/50\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0066 - val_loss: 0.0069\n",
            "Epoch 38/50\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0059 - val_loss: 0.0065\n",
            "Epoch 39/50\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0067 - val_loss: 0.0064\n",
            "Epoch 40/50\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0060 - val_loss: 0.0065\n",
            "Epoch 41/50\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0062 - val_loss: 0.0078\n",
            "Epoch 42/50\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0061 - val_loss: 0.0067\n",
            "Epoch 43/50\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0056 - val_loss: 0.0069\n",
            "Epoch 44/50\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0065 - val_loss: 0.0065\n",
            "Epoch 45/50\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0054 - val_loss: 0.0068\n",
            "Epoch 46/50\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0053 - val_loss: 0.0063\n",
            "Epoch 47/50\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0051 - val_loss: 0.0073\n",
            "Epoch 48/50\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0059 - val_loss: 0.0072\n",
            "Epoch 49/50\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0055 - val_loss: 0.0067\n",
            "Epoch 50/50\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0062 - val_loss: 0.0075\n",
            "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Results for CNN Regression (steady_state_temp_L0):\n",
            "MSE: 5.841374890759283\n",
            "MAE: 1.4903859309835426\n",
            "R²: 0.9910574537474521\n",
            "----------------------------------------\n",
            "Results for CNN Regression (steady_state_temp_L1):\n",
            "MSE: 5.821419029618046\n",
            "MAE: 1.49609055758551\n",
            "R²: 0.990982251994609\n",
            "----------------------------------------\n",
            "Results for CNN Regression (router_avg_temp_L0):\n",
            "MSE: 0.014471390493639314\n",
            "MAE: 0.08601194332980461\n",
            "R²: 0.9855337735666717\n",
            "----------------------------------------\n",
            "Results for CNN Regression (router_avg_temp_L1):\n",
            "MSE: 0.02854242143955908\n",
            "MAE: 0.11618385444649011\n",
            "R²: 0.9918420038791331\n",
            "----------------------------------------\n",
            "Results for CNN Regression (core_avg_temp_L0):\n",
            "MSE: 0.002649704192972504\n",
            "MAE: 0.038012281931790105\n",
            "R²: 0.9823628814351348\n",
            "----------------------------------------\n",
            "Results for CNN Regression (core_avg_temp_L1):\n",
            "MSE: 0.004007877762274501\n",
            "MAE: 0.049681379809650386\n",
            "R²: 0.9890396514631986\n",
            "----------------------------------------\n",
            "Results for CNN Regression (mem_avg_temp_L0):\n",
            "MSE: 0.0011172470598624612\n",
            "MAE: 0.025590330427261103\n",
            "R²: 0.9770410396957407\n",
            "----------------------------------------\n",
            "Results for CNN Regression (mem_avg_temp_L1):\n",
            "MSE: 0.001875897503310437\n",
            "MAE: 0.03373693556375969\n",
            "R²: 0.990734757401256\n",
            "----------------------------------------\n",
            "Results for CNN Regression (total_area):\n",
            "MSE: 33303666489568.082\n",
            "MAE: 4457197.448856799\n",
            "R²: 0.9993868893381147\n",
            "----------------------------------------\n",
            "Results for CNN Regression (avg_power):\n",
            "MSE: 2.4750681863182052e-17\n",
            "MAE: 3.832462144143636e-09\n",
            "R²: 0.998678314872421\n",
            "----------------------------------------\n",
            "Results for CNN Regression (avg_cores_power):\n",
            "MSE: 1.018308615827994e-17\n",
            "MAE: 2.515237744400022e-09\n",
            "R²: 0.9991376811380922\n",
            "----------------------------------------\n",
            "Results for CNN Regression (avg_routers_power):\n",
            "MSE: 2.8378959607654464e-18\n",
            "MAE: 1.1724157171036353e-09\n",
            "R²: 0.9970404806353378\n",
            "----------------------------------------\n",
            "Results for CNN Regression (avg_power_per_router):\n",
            "MSE: 1.4851092137110182e-22\n",
            "MAE: 7.697744298482043e-12\n",
            "R²: 0.9918887491032438\n",
            "----------------------------------------\n",
            "Results for CNN Regression (layer_area):\n",
            "MSE: 7795132787658.742\n",
            "MAE: 2196357.8758122744\n",
            "R²: 0.9994259758412243\n",
            "----------------------------------------\n",
            "Results for CNN Regression (area_per_core):\n",
            "MSE: 0.0\n",
            "MAE: 0.0\n",
            "R²: 1.0\n",
            "----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Load your dataset\n",
        "df = pd.read_csv('pat_dataset.csv')\n",
        "\n",
        "# Columns containing the target variables\n",
        "target_columns = ['steady_state_temp_L0', 'steady_state_temp_L1', 'router_avg_temp_L0', 'router_avg_temp_L1',\n",
        "                  'core_avg_temp_L0', 'core_avg_temp_L1', 'mem_avg_temp_L0', 'mem_avg_temp_L1',\n",
        "                  'total_area', 'avg_power', 'avg_cores_power', 'avg_routers_power', 'avg_power_per_router',\n",
        "                  'layer_area', 'area_per_core']\n",
        "\n",
        "# Split the dataset into features (X) and target variables (y)\n",
        "X = df.drop(columns=target_columns)  # Features\n",
        "y = df[target_columns]  # Targets\n",
        "\n",
        "# Identify categorical columns\n",
        "categorical_columns = ['routing_type', 'selection_strategy', 'traffic_type']\n",
        "\n",
        "# One-hot encode categorical columns\n",
        "X = pd.get_dummies(X, columns=categorical_columns, drop_first=True)\n",
        "\n",
        "# Apply log transformation to target variables (for targets with large range of values)\n",
        "y_log = np.log1p(y)  # Apply log1p transformation to all target columns\n",
        "\n",
        "# Split the data into training and test sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_log, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize RobustScaler for features\n",
        "scaler_X = RobustScaler()\n",
        "scaler_X.fit(X_train)\n",
        "X_train_scaled = scaler_X.transform(X_train)\n",
        "X_test_scaled = scaler_X.transform(X_test)\n",
        "\n",
        "# Initialize StandardScaler for target variables (log-transformed)\n",
        "scaler_y = {}\n",
        "for target in target_columns:\n",
        "    scaler_y[target] = StandardScaler()\n",
        "    y_train[target] = scaler_y[target].fit_transform(y_train[[target]])\n",
        "    y_test[target] = scaler_y[target].transform(y_test[[target]])\n",
        "\n",
        "# CNN Model (without MaxPooling1D)\n",
        "def build_cnn_model(input_shape):\n",
        "    model = models.Sequential([\n",
        "        layers.InputLayer(input_shape=input_shape),\n",
        "        layers.Conv1D(filters=64, kernel_size=3, activation='relu'),\n",
        "        layers.Conv1D(filters=128, kernel_size=3, activation='relu'),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        layers.Dense(1)  # Output layer for regression\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "    return model\n",
        "\n",
        "# CNN Regression for each target variable\n",
        "for target in target_columns:\n",
        "    print(f\"\\nEvaluating CNN model for {target}...\")\n",
        "\n",
        "    # Reshape X data for CNN\n",
        "    X_train_cnn = np.expand_dims(X_train_scaled, axis=-1)\n",
        "    X_test_cnn = np.expand_dims(X_test_scaled, axis=-1)\n",
        "\n",
        "    # Build and train CNN model\n",
        "    cnn_model = build_cnn_model(input_shape=(X_train_cnn.shape[1], 1))\n",
        "    cnn_model.fit(X_train_cnn, y_train[target], epochs=50, batch_size=32, verbose=0)\n",
        "\n",
        "    # Predict with CNN model\n",
        "    y_pred_cnn = cnn_model.predict(X_test_cnn)\n",
        "\n",
        "    # Inverse transform the predictions and targets (without reshape)\n",
        "    y_pred_cnn_rescaled = scaler_y[target].inverse_transform(y_pred_cnn)\n",
        "    y_test_rescaled = scaler_y[target].inverse_transform(y_test[target].values.reshape(-1, 1))\n",
        "\n",
        "    # Calculate evaluation metrics for CNN model\n",
        "    mse_cnn = mean_squared_error(y_test_rescaled, y_pred_cnn_rescaled)\n",
        "    mae_cnn = mean_absolute_error(y_test_rescaled, y_pred_cnn_rescaled)\n",
        "    r2_cnn = r2_score(y_test_rescaled, y_pred_cnn_rescaled)\n",
        "\n",
        "    # Print CNN results\n",
        "    print(f\"MSE: {mse_cnn}\")\n",
        "    print(f\"MAE: {mae_cnn}\")\n",
        "    print(f\"R²: {r2_cnn}\")\n",
        "    print(\"-\" * 40)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knhSj0dT-naM",
        "outputId": "2d8363a5-d3d9-4969-9e1d-93dfeb8764da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating CNN model for steady_state_temp_L0...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "MSE: 0.00043396271717479083\n",
            "MAE: 0.012335052719150315\n",
            "R²: 0.9925083713581937\n",
            "----------------------------------------\n",
            "\n",
            "Evaluating CNN model for steady_state_temp_L1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "MSE: 0.00025787358101189435\n",
            "MAE: 0.009295801393801118\n",
            "R²: 0.9956007427609966\n",
            "----------------------------------------\n",
            "\n",
            "Evaluating CNN model for router_avg_temp_L0...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "MSE: 1.1368079634073524e-05\n",
            "MAE: 0.002104409172313744\n",
            "R²: 0.9906742384448172\n",
            "----------------------------------------\n",
            "\n",
            "Evaluating CNN model for router_avg_temp_L1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "MSE: 2.8161073337503893e-05\n",
            "MAE: 0.003861251603054588\n",
            "R²: 0.9925869578368133\n",
            "----------------------------------------\n",
            "\n",
            "Evaluating CNN model for core_avg_temp_L0...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "MSE: 2.129513510623607e-06\n",
            "MAE: 0.0009543422072593446\n",
            "R²: 0.9894071113698121\n",
            "----------------------------------------\n",
            "\n",
            "Evaluating CNN model for core_avg_temp_L1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "MSE: 2.8654005133158236e-06\n",
            "MAE: 0.0011359665539711027\n",
            "R²: 0.9940271095479493\n",
            "----------------------------------------\n",
            "\n",
            "Evaluating CNN model for mem_avg_temp_L0...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "MSE: 6.612305378114421e-07\n",
            "MAE: 0.0005598726319700783\n",
            "R²: 0.9900911030086178\n",
            "----------------------------------------\n",
            "\n",
            "Evaluating CNN model for mem_avg_temp_L1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "MSE: 9.720214495178168e-07\n",
            "MAE: 0.0006565850452630733\n",
            "R²: 0.9964229294523617\n",
            "----------------------------------------\n",
            "\n",
            "Evaluating CNN model for total_area...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "MSE: 9.493477057515555e-06\n",
            "MAE: 0.002342965974088628\n",
            "R²: 0.9999859177532414\n",
            "----------------------------------------\n",
            "\n",
            "Evaluating CNN model for avg_power...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "MSE: 1.5408740920420902e-17\n",
            "MAE: 2.835133553320717e-09\n",
            "R²: 0.9991771736032806\n",
            "----------------------------------------\n",
            "\n",
            "Evaluating CNN model for avg_cores_power...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "MSE: 1.896633239144519e-18\n",
            "MAE: 9.32708022299058e-10\n",
            "R²: 0.9998393902123868\n",
            "----------------------------------------\n",
            "\n",
            "Evaluating CNN model for avg_routers_power...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "MSE: 9.212780849231061e-19\n",
            "MAE: 5.556407880032765e-10\n",
            "R²: 0.9990392386777153\n",
            "----------------------------------------\n",
            "\n",
            "Evaluating CNN model for avg_power_per_router...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "MSE: 7.263741311915782e-23\n",
            "MAE: 3.91178182853345e-12\n",
            "R²: 0.9960327477784054\n",
            "----------------------------------------\n",
            "\n",
            "Evaluating CNN model for layer_area...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "MSE: 7.294416493790209e-06\n",
            "MAE: 0.0021510899674625156\n",
            "R²: 0.9999891797478107\n",
            "----------------------------------------\n",
            "\n",
            "Evaluating CNN model for area_per_core...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "MSE: 8.69138002189672e-14\n",
            "MAE: 1.8897150256091234e-07\n",
            "R²: -3060453639324726.5\n",
            "----------------------------------------\n"
          ]
        }
      ]
    }
  ]
}