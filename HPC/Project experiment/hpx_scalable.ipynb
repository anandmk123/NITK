{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "a0Kg28iTdpCz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "# Load your dataset\n",
        "df = pd.read_csv('PAT_Dataset.csv')\n",
        "\n",
        "# Shuffle the dataset\n",
        "df = shuffle(df, random_state=42)\n",
        "\n",
        "# Columns containing the target variables\n",
        "target_columns = [\n",
        "    'steady_state_temp_L0', 'steady_state_temp_L1', 'router_avg_temp_L0', 'router_avg_temp_L1',\n",
        "    'core_avg_temp_L0', 'core_avg_temp_L1', 'mem_avg_temp_L0', 'mem_avg_temp_L1',\n",
        "    'total_area', 'avg_power', 'avg_cores_power', 'avg_routers_power', 'avg_power_per_router',\n",
        "    'layer_area', 'area_per_core'\n",
        "]\n",
        "\n",
        "# Identify categorical columns\n",
        "categorical_columns = ['routing_type', 'selection_strategy', 'traffic_type']\n",
        "\n",
        "# One-hot encode categorical columns\n",
        "X = pd.get_dummies(df.drop(columns=target_columns), columns=categorical_columns, drop_first=True)\n",
        "y = df[target_columns]\n",
        "\n",
        "# Split the data into training and test sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize StandardScaler\n",
        "scaler_X = StandardScaler()\n",
        "scaler_y = StandardScaler()\n",
        "\n",
        "# Scale the feature and target data\n",
        "X_train_scaled = scaler_X.fit_transform(X_train)\n",
        "X_test_scaled = scaler_X.transform(X_test)\n",
        "y_train_scaled = scaler_y.fit_transform(y_train)\n",
        "y_test_scaled = scaler_y.transform(y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.layers import Dropout\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n",
        "\n",
        "# Reshape the data to fit a CNN input\n",
        "# The CNN model expects a 3D input shape (samples, time steps, features), so we reshape X_train_scaled and X_test_scaled\n",
        "X_train_cnn = X_train_scaled.reshape(X_train_scaled.shape[0], X_train_scaled.shape[1], 1)  # Add 1 for the single \"channel\"\n",
        "X_test_cnn = X_test_scaled.reshape(X_test_scaled.shape[0], X_test_scaled.shape[1], 1)\n",
        "\n",
        "# Build an improved CNN model with dropout layers and deeper architecture\n",
        "cnn_model = Sequential()\n",
        "\n",
        "cnn_model.add(Conv1D(filters=64, kernel_size=3, activation='relu', padding='same', input_shape=(X_train_cnn.shape[1], 1)))\n",
        "cnn_model.add(MaxPooling1D(pool_size=2))\n",
        "cnn_model.add(Dropout(0.3))\n",
        "\n",
        "cnn_model.add(Conv1D(filters=128, kernel_size=3, activation='relu', padding='same'))\n",
        "cnn_model.add(MaxPooling1D(pool_size=2))\n",
        "cnn_model.add(Dropout(0.3))\n",
        "\n",
        "cnn_model.add(Conv1D(filters=256, kernel_size=3, activation='relu', padding='same'))\n",
        "cnn_model.add(MaxPooling1D(pool_size=2))\n",
        "cnn_model.add(Dropout(0.3))\n",
        "\n",
        "# Flatten and add dense layers for regression\n",
        "cnn_model.add(Flatten())\n",
        "cnn_model.add(Dense(128, activation='relu'))\n",
        "cnn_model.add(Dropout(0.3))\n",
        "cnn_model.add(Dense(64, activation='relu'))\n",
        "cnn_model.add(Dense(len(target_columns)))  # Output layer for all targets at once\n",
        "\n",
        "# Compile the model\n",
        "cnn_model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Set up callbacks for early stopping and learning rate reduction\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-5)\n",
        "\n",
        "# Train the model\n",
        "cnn_model.fit(X_train_cnn, y_train_scaled, epochs=50, batch_size=32, validation_split=0.2,\n",
        "              callbacks=[early_stopping, reduce_lr])\n",
        "\n",
        "# Predict using the trained CNN model\n",
        "y_pred_cnn_scaled = cnn_model.predict(X_test_cnn)\n",
        "\n",
        "# Prepare evaluation results as before\n",
        "cnn_evaluation_results = []\n",
        "print(\"CNN Performance (per target variable):\")\n",
        "\n",
        "for i, target in enumerate(target_columns):\n",
        "    y_test_target = y_test_scaled[:, i]\n",
        "    y_pred_target = y_pred_cnn_scaled[:, i]\n",
        "    mse = mean_squared_error(y_test_target, y_pred_target)\n",
        "    mae = mean_absolute_error(y_test_target, y_pred_target)\n",
        "    r2 = r2_score(y_test_target, y_pred_target)\n",
        "    cnn_evaluation_results.append({\n",
        "        'algorithm': 'CNN',\n",
        "        'target': target,\n",
        "        'MSE': mse,\n",
        "        'MAE': mae,\n",
        "        'R²': r2\n",
        "    })\n",
        "    print(f\"\\nTarget: {target}\")\n",
        "    print(\"MSE:\", mse)\n",
        "    print(\"MAE:\", mae)\n",
        "    print(\"R²:\", r2)\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "# Results DataFrame\n",
        "cnn_evaluation_df = pd.DataFrame(cnn_evaluation_results)\n",
        "print(\"\\nCNN Evaluation Results DataFrame:\")\n",
        "print(cnn_evaluation_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lN83R81Bd18c",
        "outputId": "a1abd246-927e-4b38-b53c-2d09cff47aff"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - loss: 0.5592 - val_loss: 0.1748 - learning_rate: 0.0010\n",
            "Epoch 2/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.2413 - val_loss: 0.0981 - learning_rate: 0.0010\n",
            "Epoch 3/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.1725 - val_loss: 0.0930 - learning_rate: 0.0010\n",
            "Epoch 4/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.1461 - val_loss: 0.0641 - learning_rate: 0.0010\n",
            "Epoch 5/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.1270 - val_loss: 0.0554 - learning_rate: 0.0010\n",
            "Epoch 6/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - loss: 0.1149 - val_loss: 0.0479 - learning_rate: 0.0010\n",
            "Epoch 7/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - loss: 0.1096 - val_loss: 0.0532 - learning_rate: 0.0010\n",
            "Epoch 8/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.1001 - val_loss: 0.0492 - learning_rate: 0.0010\n",
            "Epoch 9/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0931 - val_loss: 0.0395 - learning_rate: 0.0010\n",
            "Epoch 10/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0908 - val_loss: 0.0361 - learning_rate: 0.0010\n",
            "Epoch 11/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0864 - val_loss: 0.0368 - learning_rate: 0.0010\n",
            "Epoch 12/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - loss: 0.0840 - val_loss: 0.0300 - learning_rate: 0.0010\n",
            "Epoch 13/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0789 - val_loss: 0.0260 - learning_rate: 0.0010\n",
            "Epoch 14/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0710 - val_loss: 0.0283 - learning_rate: 0.0010\n",
            "Epoch 15/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0729 - val_loss: 0.0288 - learning_rate: 0.0010\n",
            "Epoch 16/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0763 - val_loss: 0.0389 - learning_rate: 0.0010\n",
            "Epoch 17/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0663 - val_loss: 0.0211 - learning_rate: 2.0000e-04\n",
            "Epoch 18/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0612 - val_loss: 0.0190 - learning_rate: 2.0000e-04\n",
            "Epoch 19/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0550 - val_loss: 0.0196 - learning_rate: 2.0000e-04\n",
            "Epoch 20/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0561 - val_loss: 0.0209 - learning_rate: 2.0000e-04\n",
            "Epoch 21/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0534 - val_loss: 0.0194 - learning_rate: 2.0000e-04\n",
            "Epoch 22/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - loss: 0.0523 - val_loss: 0.0182 - learning_rate: 4.0000e-05\n",
            "Epoch 23/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0509 - val_loss: 0.0189 - learning_rate: 4.0000e-05\n",
            "Epoch 24/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0499 - val_loss: 0.0181 - learning_rate: 4.0000e-05\n",
            "Epoch 25/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0506 - val_loss: 0.0180 - learning_rate: 4.0000e-05\n",
            "Epoch 26/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0495 - val_loss: 0.0177 - learning_rate: 4.0000e-05\n",
            "Epoch 27/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0509 - val_loss: 0.0179 - learning_rate: 4.0000e-05\n",
            "Epoch 28/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.0506 - val_loss: 0.0182 - learning_rate: 4.0000e-05\n",
            "Epoch 29/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0486 - val_loss: 0.0177 - learning_rate: 4.0000e-05\n",
            "Epoch 30/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - loss: 0.0491 - val_loss: 0.0176 - learning_rate: 1.0000e-05\n",
            "Epoch 31/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0493 - val_loss: 0.0175 - learning_rate: 1.0000e-05\n",
            "Epoch 32/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - loss: 0.0477 - val_loss: 0.0174 - learning_rate: 1.0000e-05\n",
            "Epoch 33/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - loss: 0.0489 - val_loss: 0.0173 - learning_rate: 1.0000e-05\n",
            "Epoch 34/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0486 - val_loss: 0.0176 - learning_rate: 1.0000e-05\n",
            "Epoch 35/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - loss: 0.0495 - val_loss: 0.0172 - learning_rate: 1.0000e-05\n",
            "Epoch 36/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0500 - val_loss: 0.0172 - learning_rate: 1.0000e-05\n",
            "Epoch 37/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - loss: 0.0481 - val_loss: 0.0175 - learning_rate: 1.0000e-05\n",
            "Epoch 38/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0487 - val_loss: 0.0173 - learning_rate: 1.0000e-05\n",
            "Epoch 39/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0492 - val_loss: 0.0171 - learning_rate: 1.0000e-05\n",
            "Epoch 40/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0471 - val_loss: 0.0172 - learning_rate: 1.0000e-05\n",
            "Epoch 41/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0487 - val_loss: 0.0174 - learning_rate: 1.0000e-05\n",
            "Epoch 42/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.0482 - val_loss: 0.0175 - learning_rate: 1.0000e-05\n",
            "Epoch 43/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0490 - val_loss: 0.0176 - learning_rate: 1.0000e-05\n",
            "Epoch 44/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - loss: 0.0464 - val_loss: 0.0171 - learning_rate: 1.0000e-05\n",
            "Epoch 45/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0477 - val_loss: 0.0169 - learning_rate: 1.0000e-05\n",
            "Epoch 46/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - loss: 0.0491 - val_loss: 0.0171 - learning_rate: 1.0000e-05\n",
            "Epoch 47/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0463 - val_loss: 0.0169 - learning_rate: 1.0000e-05\n",
            "Epoch 48/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0470 - val_loss: 0.0171 - learning_rate: 1.0000e-05\n",
            "Epoch 49/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.0502 - val_loss: 0.0174 - learning_rate: 1.0000e-05\n",
            "Epoch 50/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0456 - val_loss: 0.0174 - learning_rate: 1.0000e-05\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "CNN Performance (per target variable):\n",
            "\n",
            "Target: steady_state_temp_L0\n",
            "MSE: 0.027020214073665064\n",
            "MAE: 0.10064539245815755\n",
            "R²: 0.9718678477826566\n",
            "------------------------------\n",
            "\n",
            "Target: steady_state_temp_L1\n",
            "MSE: 0.0267511612408056\n",
            "MAE: 0.09939859391390524\n",
            "R²: 0.9721586733199526\n",
            "------------------------------\n",
            "\n",
            "Target: router_avg_temp_L0\n",
            "MSE: 0.026713511751596662\n",
            "MAE: 0.09341508554987718\n",
            "R²: 0.9732058373738272\n",
            "------------------------------\n",
            "\n",
            "Target: router_avg_temp_L1\n",
            "MSE: 0.01918007727058492\n",
            "MAE: 0.07148761381954137\n",
            "R²: 0.9817073657309319\n",
            "------------------------------\n",
            "\n",
            "Target: core_avg_temp_L0\n",
            "MSE: 0.02993280203885679\n",
            "MAE: 0.11299360818611413\n",
            "R²: 0.9696151805052464\n",
            "------------------------------\n",
            "\n",
            "Target: core_avg_temp_L1\n",
            "MSE: 0.025068881891124686\n",
            "MAE: 0.0973816203096477\n",
            "R²: 0.9752337006943232\n",
            "------------------------------\n",
            "\n",
            "Target: mem_avg_temp_L0\n",
            "MSE: 0.03759367883797663\n",
            "MAE: 0.12196712414048463\n",
            "R²: 0.9625854549516663\n",
            "------------------------------\n",
            "\n",
            "Target: mem_avg_temp_L1\n",
            "MSE: 0.0217085293578216\n",
            "MAE: 0.08563553009262513\n",
            "R²: 0.9788806841259379\n",
            "------------------------------\n",
            "\n",
            "Target: total_area\n",
            "MSE: 0.004412317253309667\n",
            "MAE: 0.05176942168839584\n",
            "R²: 0.9956850768870278\n",
            "------------------------------\n",
            "\n",
            "Target: avg_power\n",
            "MSE: 0.004834609184305908\n",
            "MAE: 0.05212178421194802\n",
            "R²: 0.9951615110925419\n",
            "------------------------------\n",
            "\n",
            "Target: avg_cores_power\n",
            "MSE: 0.0043781369849899025\n",
            "MAE: 0.05109220894112798\n",
            "R²: 0.9956493593760173\n",
            "------------------------------\n",
            "\n",
            "Target: avg_routers_power\n",
            "MSE: 0.007064883173373214\n",
            "MAE: 0.055858242305314415\n",
            "R²: 0.9927688837556724\n",
            "------------------------------\n",
            "\n",
            "Target: avg_power_per_router\n",
            "MSE: 0.013192858190465218\n",
            "MAE: 0.07703278390158472\n",
            "R²: 0.9865128979527765\n",
            "------------------------------\n",
            "\n",
            "Target: layer_area\n",
            "MSE: 0.004265792171286209\n",
            "MAE: 0.05102594609113683\n",
            "R²: 0.9958283666783337\n",
            "------------------------------\n",
            "\n",
            "Target: area_per_core\n",
            "MSE: 3.647499705409991e-14\n",
            "MAE: 1.3225279327285245e-07\n",
            "R²: 0.0\n",
            "------------------------------\n",
            "\n",
            "CNN Evaluation Results DataFrame:\n",
            "   algorithm                target           MSE           MAE        R²\n",
            "0        CNN  steady_state_temp_L0  2.702021e-02  1.006454e-01  0.971868\n",
            "1        CNN  steady_state_temp_L1  2.675116e-02  9.939859e-02  0.972159\n",
            "2        CNN    router_avg_temp_L0  2.671351e-02  9.341509e-02  0.973206\n",
            "3        CNN    router_avg_temp_L1  1.918008e-02  7.148761e-02  0.981707\n",
            "4        CNN      core_avg_temp_L0  2.993280e-02  1.129936e-01  0.969615\n",
            "5        CNN      core_avg_temp_L1  2.506888e-02  9.738162e-02  0.975234\n",
            "6        CNN       mem_avg_temp_L0  3.759368e-02  1.219671e-01  0.962585\n",
            "7        CNN       mem_avg_temp_L1  2.170853e-02  8.563553e-02  0.978881\n",
            "8        CNN            total_area  4.412317e-03  5.176942e-02  0.995685\n",
            "9        CNN             avg_power  4.834609e-03  5.212178e-02  0.995162\n",
            "10       CNN       avg_cores_power  4.378137e-03  5.109221e-02  0.995649\n",
            "11       CNN     avg_routers_power  7.064883e-03  5.585824e-02  0.992769\n",
            "12       CNN  avg_power_per_router  1.319286e-02  7.703278e-02  0.986513\n",
            "13       CNN            layer_area  4.265792e-03  5.102595e-02  0.995828\n",
            "14       CNN         area_per_core  3.647500e-14  1.322528e-07  0.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "new_data = pd.DataFrame({\n",
        "    'dimx': [75],\n",
        "    'dimy': [75],\n",
        "    'dimz': [2],\n",
        "    'buffer_size': [10],\n",
        "    'packet_size_min': [4],\n",
        "    'packet_size_max': [8],\n",
        "    'routing_type_xyz': [1],  # Make sure to align with the encoded columns\n",
        "    'selection_strategy_thermal': [1],\n",
        "    'traffic_type_random': [1],\n",
        "    'injection_rate': [0.05]\n",
        "})\n",
        "\n",
        "# Ensure all columns are present (including any missing dummy variables from the training data)\n",
        "# Missing columns in new_data are filled with 0s\n",
        "for col in X.columns:\n",
        "    if col not in new_data:\n",
        "        new_data[col] = 0\n",
        "\n",
        "# Reorder the new_data columns to match the original feature order\n",
        "new_data = new_data[X.columns]\n",
        "\n",
        "# Scale the new data using the previously fitted scaler\n",
        "new_data_scaled = scaler_X.transform(new_data)\n",
        "\n",
        "# Reshape the scaled data to fit the CNN input shape\n",
        "new_data_cnn = new_data_scaled.reshape(1, new_data_scaled.shape[1], 1)  # Shape (1, num_features, 1)\n",
        "\n",
        "# Make predictions with the CNN model\n",
        "new_data_pred_scaled = cnn_model.predict(new_data_cnn)\n",
        "\n",
        "# Inverse scale the predictions to get original scale\n",
        "new_data_pred = scaler_y.inverse_transform(new_data_pred_scaled)\n",
        "\n",
        "# Convert the prediction to a DataFrame for readability\n",
        "predictions_df = pd.DataFrame(new_data_pred, columns=target_columns)\n",
        "\n",
        "# Display the predictions\n",
        "print(\"Predictions for the new data:\")\n",
        "print(predictions_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ZcEIpwyd8Cf",
        "outputId": "90705673-6264-4715-ca71-6c8ec96b5f53"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step\n",
            "Predictions for the new data:\n",
            "   steady_state_temp_L0  steady_state_temp_L1  router_avg_temp_L0  \\\n",
            "0            320.988098            239.610153           31.341198   \n",
            "\n",
            "   router_avg_temp_L1  core_avg_temp_L0  core_avg_temp_L1  mem_avg_temp_L0  \\\n",
            "0           28.574923         26.519922         26.969509        26.046755   \n",
            "\n",
            "   mem_avg_temp_L1    total_area  avg_power  avg_cores_power  \\\n",
            "0        26.257633  8.420159e+09   0.000006         0.000004   \n",
            "\n",
            "   avg_routers_power  avg_power_per_router    layer_area  area_per_core  \n",
            "0           0.000001          1.240144e-09  4.124060e+09      4695230.0  \n"
          ]
        }
      ]
    }
  ]
}